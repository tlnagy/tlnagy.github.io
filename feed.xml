<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://tlnagy.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://tlnagy.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-11-05T01:22:24+00:00</updated><id>https://tlnagy.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Inside Lines Equipment Porteur Rackbag Review</title><link href="https://tlnagy.github.io/blog/2018/ile-rackbag/" rel="alternate" type="text/html" title="Inside Lines Equipment Porteur Rackbag Review"/><published>2018-10-13T12:00:00+00:00</published><updated>2018-10-13T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2018/ile-rackbag</id><content type="html" xml:base="https://tlnagy.github.io/blog/2018/ile-rackbag/"><![CDATA[<p>Cycling around San Francisco almost everyday for the past year and a half made me want to look for a better way to carry stuff with me.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0842.JPG" alt=""/></p> <p>I tried the rear rack with baskets approach, but I kept clipping my heels on the baskets and having lots of weight in the back made my bike fish tail too much for my liking. It especially made the bike handle poorly at low speeds and when walking the bike since I hold the bike by the stem<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>.</p> <p>Convinced, I picked up a front porteur rack, the <a href="https://www.amazon.com/Origin8-Classique-Cargo-Front-Rack/dp/B00B135SSE">Origin 8 Classique</a>, and immediately preferred it to my old rear rack set up. However, I realized quickly that my bungee cord solution for attaching stuff to the front rack left a lot to be desired.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0836.JPG" alt=""/></p> <p>After looking at a lot of different porteur bags, I ended up swinging by <a href="https://ilequipment.com/">Inside Lines Equipment</a>’s shop over in Berkeley and played around with their made-in-Berkeley Rackbag. They had it in a beautiful limited-edition copper/gold color in the XPAC material with a fully waterproof tarpulin liner. Unlike the other XPAC colors, this color was matte and did not have that technical-looking sheen to it. XPAC is a great bag material, it feels very solid and holds its shape well, while also being lightweight. I had to get it and now that I’ve had it for about two weeks I thought I would give a quick review of what I like and what I don’t.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0840.JPG" alt=""/></p> <p>One of my favorite features are the two easily accessible pockets at the rear of the bag that face you while on the bike. These are great for storing things that you need to be easily accessible on the go. I keep my Abus U-lock in one pocket and miscellaneous things I need in the other. They are quite large and you can easily fit even large snacks, smartphones, etc.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0864.JPG" alt=""/></p> <p>It attaches via two easily adjustable straps on the bottom of the bag. Once you set them to work for your rack, you can attach it and go pretty quickly. I can attach it based on feel now so I don’t need to squat down any more to attach it.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0866.JPG" alt=""/></p> <p>Let me go ahead and say that this bag is huge, it can expand to hold 42L of your stuff. You’ll probably hit the weight limits of your front rack before filling this thing up. It has some straps hidden in the velco flap to strap on oversized items.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0865.JPG" alt=""/></p> <p>Like any porteur bag, it looks the most at home on the bike, but it can pass as a messenger bag whenever you need to leave the bike behind. The flat, rigid base makes it have unique profile that might not be for everyone.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0867.JPG" alt=""/></p> <p>However, that leads me to probably my least favorite aspects of the bag: there isn’t a good hand hold if the shoulder strap is attached. They include a nice grab strap, but that can only be used in place of the the shoulder strap, not in addition to. The only other complaint I have is that it would be nice to have some kind of organization inside the main pocket because everything just jostles in the same cavernous hole.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0868.JPG" alt=""/></p> <p>Overall, I’m very happy with my purchase. It very freeing to not have to put everything on my back while riding and I find that I much prefer having the weight in the front. The ILE Porteur Rackbag is a high-quality, lightweight, versatile, and waterproof bag that I’m sure will last me a very long time.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0841.JPG" alt=""/></p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p><a href="https://cetmacargo.com/pages/cetma-racks-info">Cetma Cargo</a>’s reasons for preferring a front rack, in case the link goes down</p> <blockquote> <p>Four barely compelling reasons for using a front rack:</p> <ol> <li> <p>The rear wheel is inherently weaker than the front wheel due to its asymmetrical build, offset hub, and torque input.</p> </li> <li> <p>The rear part of the frame is where almost all frames break. The thin chain stays and seat stays are notorious weak spots.</p> </li> <li> <p>Carrying weight on a rear rack makes the entire bike feel unstable and top-heavy. Put a heavy box on a rear rack and try to ride down the street. The entire frame flexes and the bike tries to lay down. Come to a stop and it gets downright scary. Transporting that box becomes a precarious balancing act. It’s easier to handle cargo when it’s up front near your hands.</p> </li> <li> <p>Rear-loaded freight remains behind you while you ride (duh), and you can’t see if it’s shifting or about to fall. It’s easier to keep an eye on cargo when it’s in front of you.)</p> </li> </ol> <p>- Cetma Cargo</p> </blockquote> <p><a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Tamas Nagy</name></author><category term="cycling"/><category term="review"/><summary type="html"><![CDATA[Cycling around San Francisco almost everyday for the past year and a half made me want to look for a better way to carry stuff with me.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tlnagy.github.io/2018-10-13-ile-rackbag/IMG_0841.JPG"/><media:content medium="image" url="https://tlnagy.github.io/2018-10-13-ile-rackbag/IMG_0841.JPG" xmlns:media="http://search.yahoo.com/mrss/"/></entry><entry><title type="html">A deep dive into the Stellar public network (Part 1)</title><link href="https://tlnagy.github.io/blog/2018/stellar-network-analysis/" rel="alternate" type="text/html" title="A deep dive into the Stellar public network (Part 1)"/><published>2018-03-18T12:00:00+00:00</published><updated>2018-03-18T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2018/stellar-network-analysis</id><content type="html" xml:base="https://tlnagy.github.io/blog/2018/stellar-network-analysis/"><![CDATA[<p>One of the basic tenets of public blockchains is that all account and transactional information is open to anyone to see. While I’m pretty certain that most cryptocurrencies will eventually adopt some type of zero-knowledge cryptography (e.g. <a href="https://z.cash/technology/zksnarks.html">zk-snarks</a>) that would make this sort of analysis impossible or much more difficult, many still have everything recorded in the clear, e.g. the <a href="https://stellar.org">Stellar network</a> and its corresponding currency, Lumens (XLM).</p> <p>Stellar is an interesting project because it does not rely on the extremely wasteful proof-of-work consensus method (used by Bitcoin and Ethereum). It instead uses the Stellar Consensus Protocol (SCP), which is a form of a federated Byzantine agreement. There’s a <a href="https://medium.com/a-stellar-journey/on-worldwide-consensus-359e9eb3e949">technical summary</a> and a <a href="https://www.stellar.org/papers/stellar-consensus-protocol.pdf">white paper</a> that both explain how SCP works<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>. Its key benefits are that it is both fast (1000+ transactions per second) and environmentally friendly (extremely low energy costs).</p> <p><strong>Okay, so Stellar is cool, but how are people using it?</strong> This was the question that spawned this analysis. I wanted to see what I could find out from the Stellar’s public blockchain about how people (and bots) were using it. This is part 1 of what I hope is a multipart dive into the Stellar network<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>. Some questions I hope to answer:</p> <ol> <li><a href="#account-inflation-destination-distribution">What is the inflation destination distribution across accounts?</a></li> <li><a href="#correlation-between-account-balance-and-age">Is there a correlation between account balance and age?</a></li> <li>Are most accounts just holding<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup> lumens or are they actually moving around?</li> <li>What is the topology of the transaction graph? Is it more hub-and-spoke or more Erdős-Rényi like?</li> <li>Can I detect when major giveaways and changes to the protocol happened?</li> </ol> <h2 id="getting-the-data">Getting the data</h2> <p>While Stellar’s documentation is surprisingly good compared to other cryptoprojects, it took a bit of finagling to get everything to work, but that might be more indicative of my newness to the whole scene.</p> <p>The first step was actually getting the data. Stellar has a convenient RESTful API for many things via <a href="https://github.com/stellar/horizon">Horizon</a>, but that isn’t <a href="https://stellar.stackexchange.com/questions/729/possible-to-get-a-list-of-account-holders-satisfying-certain-criteria-using-hori?noredirect=1#comment597_729">sufficient</a> for my needs so I needed to set up a full node locally.</p> <h3 id="setting-up-a-local-node">Setting up a local node</h3> <p>The easiest way to do this is via <a href="https://www.docker.com/"><code class="language-plaintext highlighter-rouge">Docker</code></a> and once you install it, provisioning a Stellar node is a easy<sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup> as running the following command in your terminal (don’t type the preceding <code class="language-plaintext highlighter-rouge">$</code>):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker run --rm -it -p "8000:8000" -p "5432:5432" -v ~/Documents/stellar:/opt/stellar --name stellar stellar/quickstart --pubnet
</code></pre></div></div> <p><strong>Make sure to enter a password in for the PostgreSQL database and that you write it down. You’ll need it to connect to the database later.</strong></p> <p>The above command tells Docker to download the <a href="https://github.com/stellar/docker-stellar-core-horizon"><code class="language-plaintext highlighter-rouge">stellar/quickstart</code></a> Docker image and create a volume at <code class="language-plaintext highlighter-rouge">~/Documents/stellar</code> where the Stellar node will store all of its data. It will also expose the HTML and PostgreSQL ports locally too. We’ll need the latter one to actually access the data. Finally, the <code class="language-plaintext highlighter-rouge">--pubnet</code> flag tells the node to use the public network (i.e. real lumens).</p> <p>Once you run this command you’ll need to wait till the node is synchronized with the network. You can check its progress by connecting to the Docker container</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker exec -it stellar /bin/bash
</code></pre></div></div> <p>which opens a connection to the container’s shell. You can then run</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ stellar-core --c 'info'
</code></pre></div></div> <p>to ask query the state of your node. The key thing is to look at the <code class="language-plaintext highlighter-rouge">"state"</code> value below, it should eventually read <code class="language-plaintext highlighter-rouge">"Synced!"</code></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Content-Length: 761
Content-Type: application/json

2018-03-18T02:55:14.579 GACID [default INFO] {
   "info" : {
      "authenticated_peers_count" : 8,
      "build" : "v9.1.0",
      "ledger" : {
         "age" : 8,
         "baseFee" : 100,
         "baseReserve" : 5000000,
         "closeTime" : 1521341706,
         "hash" : "260f4e039fb7835c376b0402fec928049c2071412c1fdfcf220445b67a95ad7e",
         "num" : 16874829,
         "version" : 9
      },
      "network" : "Public Global Stellar Network ; September 2015",
      "pending_peers_count" : 0,
      "protocol_version" : 9,
      "quorum" : {
         "16874828" : {
            "agree" : 5,
            "disagree" : 0,
            "fail_at" : 2,
            "hash" : "ba2fc8",
            "missing" : 0,
            "phase" : "EXTERNALIZE"
         }
      },
      "state" : "Synced!"
   }
}
</code></pre></div></div> <p>The last ledger was <a href="https://stellarchain.io/ledger/16874860">16874860</a> when I shutdown my node to prevent the data from mutating during my analysis.</p> <h3 id="querying-the-data">Querying the data</h3> <p>I used <a href="https://eggerapps.at/postico/">Postico</a> to actually query the data, but any PostgreSQL client will work.</p> <p><img src="/assets/images/2018-03-18-stellar-network-analysis/f6930827.png" alt=""/></p> <p>You’ll need to tell it to connect to the PostgreSQL instance by telling it to connect to localhost on port 5432, with <code class="language-plaintext highlighter-rouge">stellar</code> as the username and the password you entered from above. The main database we’ll be interacting with is <code class="language-plaintext highlighter-rouge">core</code>. You can then execute any SQL query against the database.</p> <h2 id="analysis">Analysis</h2> <p>Now to the fun part, actually answering some questions! All my analysis was done in <a href="https://julialang.org">Julia</a> and my jupyter notebook is available <a href="https://gist.github.com/tlnagy/13c88fb4987ab4081cbc043b31a5e018">here</a>.</p> <h3 id="account-inflation-destination-distribution">Account inflation destination distribution</h3> <p>One major concept of the Stellar network is the concept of <a href="https://www.stellar.org/developers/guides/concepts/inflation.html">inflation</a>.</p> <blockquote> <p>The Stellar distributed network has a built-in, fixed, nominal inflation mechanism. New lumens are added to the network at the rate of 1% each year. Each week, the protocol distributes these lumens to any account that gets over .05% of the “votes” from other accounts in the network.</p> </blockquote> <p>My understanding is that lumens that are distributed are both new lumens that are added (at the rate of 1% of each year) and the lumens collected from transaction fees<sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">5</a></sup>. But…lumens are only distributed if an inflation destination is set. I wanted to look at the inflation destinations ordered by the total amount of XLM in the accounts pointed at each destination (on left) and the number of accounts pointed at each destination (on right).</p> <p><img src="/assets/images/2018-03-18-stellar-network-analysis/inflationdest.svg" alt=""/></p> <p>First thing, there are a lot of accounts without a set inflation destination (i.e. a NULL destination). 6.7 billion lumens are not earning inflation, which works out to 37% of all distributed lumens. It’s even worse if you look at the level of accounts. 76% percent of all accounts aren’t earning any inflation! The biggest community pool (balance-wise) is <a href="https://lumenaut.net/">GCCD..NAUT</a>, which is one of the newer pools that has no fees. Pretty cool that it caught on so quick.</p> <p>I don’t understand why manual setting of the inflation destination is necessary. Why can’t the lumens be distributed to every account equally? I just find it unfortunate that the majority of accounts aren’t taking advantage of the inflation payouts.</p> <h3 id="correlation-between-account-balance-and-age">Correlation between account balance and age</h3> <p>Another thing I wanted to look at is if there was any correlation between the age of an account and the size of the balance. The account creation time is not stored, but there is a last modified time. Plotting the 2D histogram of the last modified time versus balance size gives this:</p> <p><img src="/assets/images/2018-03-18-stellar-network-analysis/balanceage.svg" alt=""/></p> <p>Couple interesting points. You can clearly see when the minimum account balance was lowered from 10 XLM to 0.5 XLM in <a href="https://github.com/stellar/docs/commit/9c0100d80d32dfff9d9d071b77def6bf8599b151#diff-fe29f1f4bf5e6ceed24a2a27a5d241c6">January</a>. There is also a strip around 5000 XLM, which are probably old accounts that received free lumens, but were forgotten.</p> <p>In the next part, I’ll map transactions to each account so then I’ll be able to find the oldest transaction for each account to determine its age instead of using the last modified time. I also hope to answer the rest of the questions outlined above.</p> <p>If you made it this far and have any more ideas for what I could look into, tweet at me (<a href="https://twitter.com/tlngy">\@tlngy</a>).</p> <p>some time in the future. Hopefully, it will help me a better understanding of the limitations and weaknesses of the protocol design.</p> <p>locally on my MacOS machine, but ran into issues with the <a href="https://stellar.stackexchange.com/questions/731/running-into-an-invalid-quorum-set-error-when-running-stellar-core?noredirect=1#comment594_731">config file</a>. Apparently, the default config file ships with a non-functional quorum-set (probably a good thing to make sure people actually think about which nodes they list here, heh).</p> <p>the miners.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>I plan to write an intuitive description of how SCP works on this blog <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>That depends heavily on the amount of free time I have, heh. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>hodling <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:4"> <p>I originally tried setting up an instance by compiling stellar-core <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:5"> <p>In proof-of-work currencies, the transaction fees are much higher and paid to <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Tamas Nagy</name></author><category term="crypto"/><summary type="html"><![CDATA[One of the basic tenets of public blockchains is that all account and transactional information is open to anyone to see. While I’m pretty certain that most cryptocurrencies will eventually adopt some type of zero-knowledge cryptography (e.g. zk-snarks) that would make this sort of analysis impossible or much more difficult, many still have everything recorded in the clear, e.g. the Stellar network and its corresponding currency, Lumens (XLM).]]></summary></entry><entry><title type="html">Keeping a reading list</title><link href="https://tlnagy.github.io/blog/2018/reading-list/" rel="alternate" type="text/html" title="Keeping a reading list"/><published>2018-01-29T12:00:00+00:00</published><updated>2018-01-29T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2018/reading-list</id><content type="html" xml:base="https://tlnagy.github.io/blog/2018/reading-list/"><![CDATA[<p><img src="/assets/images/IMG_20180129_192927.jpg" alt=""/></p> <p><br/></p> <p>I recently received as a gift a replacement for my long deceased third- generation Kindle. As I restart my reading habit with my new friend, I thought it would be nice to begin keeping a reading list. One that would include, not only what I have read, but also what I’m planning to read. And as I move items to the “Have Read” section, I plan to write a few sentences to jog my memory about each book in the future. This way I might be able to stave off some of the fogginess that comes with time.</p> <p><br/></p> <p>My target audience with this endeavor is myself, but perhaps you can find something interesting in it as well. Take a <a href="/reading/">look</a>.</p>]]></content><author><name>Tamas Nagy</name></author><category term="meta"/><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tlnagy.github.io/IMG_20180129_192927.jpg"/><media:content medium="image" url="https://tlnagy.github.io/IMG_20180129_192927.jpg" xmlns:media="http://search.yahoo.com/mrss/"/></entry><entry><title type="html">UCSF should match employee donations to SFBike</title><link href="https://tlnagy.github.io/blog/2017/ucsf-sfbike-match/" rel="alternate" type="text/html" title="UCSF should match employee donations to SFBike"/><published>2017-12-17T12:00:00+00:00</published><updated>2017-12-17T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2017/ucsf-sfbike-match</id><content type="html" xml:base="https://tlnagy.github.io/blog/2017/ucsf-sfbike-match/"><![CDATA[<p>Cycling is a great way to commute to work and to stay healthy. It is associated with reduced risk for cardiovascular disease, cancer, and all cause mortality [@Celis-Morales2017]. UCSF already recognizes this and <a href="http://campuslifeservices.ucsf.edu/transportation/services/biking">promotes biking</a> as a transportation mode. Citywide, bikes make up about <a href="https://www.sfmta.com/blog/san-francisco%E2%80%99s-surge-biking-continues">4.4% of all commute trips</a> (as of 2014).</p> <p>Unfortunately, the cycling infrastructure in San Francisco still needs a lot of work to be a viable option for students and staff. Too many people are <a href="http://sfgov.org/scorecards/traffic-fatalities">injured or killed</a> each year on our streets. We only have <a href="https://www.sfmta.com/blog/san-francisco%E2%80%99s-surge-biking-continues">13 miles of protected bike lanes</a> and a single protected intersection in the entire city. Researchers in Montreal have found that such infrastructure is used 2.5x times more often than the unprotected bike lanes common in San Francisco [@Lusk2011]. Thus, in order to grow the cycling mode-share among UCSF employees, university officials should also focus on advocating in City Hall to get better infrastructure built. As the second biggest employer within the city limits, UCSF’s desires carry a lot of weight and pushing for better, safer infrastructure would benefit the health of the city’s population.</p> <p>It is especially pressing now that we have our first Ford GoBike station at Mission Bay and we’re slated to get three more in 2018, plus the first one at Parnassus soon after. It would be a mistake to not ramp up advocacy at the same time to ensure that students and staff feel comfortable and safe while using bike share around our campuses.</p> <p>There is already a group dedicated to promoting cycling as a transportation mode within San Francisco, the San Francisco Bike Coalition. They <a href="http://www.sfbike.org/our-work/">advocate</a> for better infrastructure and help train people in urban biking. They have a great presence at City Hall. UCSF already offers a small <a href="http://campuslifeservices.ucsf.edu/transportation/services/biking">discount</a> to join the SF Bike Coalition. I believe UCSF should go further and offer to match student and staff donations to SF Bike. A $35 donation plus a $35 match would go further than than a discount on the $35 membership.</p> <p>Our tagline is</p> <blockquote> <p>UCSF: Advancing Health Worldwide</p> </blockquote> <p>Matching employee donations would help advance health here in San Francisco among UCSF’s own personnel by making bike commuting more attractive and more common.</p> <h2 id="references">References</h2>]]></content><author><name>Tamas Nagy</name></author><category term="random"/><summary type="html"><![CDATA[Cycling is a great way to commute to work and to stay healthy. It is associated with reduced risk for cardiovascular disease, cancer, and all cause mortality [@Celis-Morales2017]. UCSF already recognizes this and promotes biking as a transportation mode. Citywide, bikes make up about 4.4% of all commute trips (as of 2014).]]></summary></entry><entry><title type="html">Active matter modeling</title><link href="https://tlnagy.github.io/blog/2017/microtubule-vortices/" rel="alternate" type="text/html" title="Active matter modeling"/><published>2017-09-07T12:00:00+00:00</published><updated>2017-09-07T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2017/microtubule-vortices</id><content type="html" xml:base="https://tlnagy.github.io/blog/2017/microtubule-vortices/"><![CDATA[<p>Yesterday was the systems biology module of the iPQB bootcamp here at UCSF. I was in charge of the modeling section and I decided to try to get the students to model the relatively simple active matter system from @Sumino2012-dc since it was relatively straightforward, very visual, and shows complex emergent properties from simple rules (See Figure 1). Active matter systems are ubiquitous nonequilibrium condensed systems whose “unifying characteristic is that they are <strong>composed of self-driven units, active particles, each capable of converting stored or ambient free energy into systematic movement</strong>” [@Marchetti2013]. An <em>in vitro</em> microtubule and dynein system, like the one we’re investigating here, is much more controlled and reproducible compared to the flocking of birds or fish and thus serves as a nice model system in which to study active matter.</p> <p><img src="/assets/images/2017-09-07-microtubule-vortices/0de43a55.png" alt="Figure 1A-B from @Sumino2012-dc. Cy3 labeled microtubules form vortices when placed on dynein-c coated glass coverslips in the presence of ATP"/></p> <p>The authors proposed a relatively simple model that could recapitulate this phenomenon. They modeled the behavior of the microtubules as a biased Ornstein–Uhlenbeck process where the microtubules moved at a constant velocity in a direction, $\theta_i$, that was updated by an angular velocity, $\omega_i$, at each time step. They added some normal brownian noise to $\omega_i$ with mean $\xi_{\mu}$ and standard deviation $\xi_{\sigma}$. They noticed that the microtubules had a slight clockwise curvature preference and that after relaxation time $\lambda$, the angular velocity $\omega_i$ would approach the preferred angular velocity, $\omega_0$.</p> <p>@Sumino2012-dc also noted that microtubules would almost always align or anti-align after collisions (they would sometimes stall or cross). They modeled this by taking the aggregate angle of all neighbors of a microtubule that are within a certain distance from the microtubule. This was then weighted by a parameter $A$ that controls the relative influence of other microtubules.</p> <p>Mathematically, this can be expressed in the following non-dimensionalized form:</p> \[\begin{align} \frac{d\Omega_i}{dT} &amp;= - \frac{1}{\lambda}\left(\Omega_i - \Omega_0\right) + \textrm{Normal}(\xi_{\mu}, \xi_{\sigma})\\ \frac{d\theta_i}{dT} &amp;= \Omega_i + \frac{A}{N_i(T)} \sum_{j \sim i} \sin\left(2(\theta_j - \theta_i)\right) \\ \frac{d\mathbf{X_i}}{dT} &amp;= \mathbf{e_x}\cos \theta_i + \mathbf{e_y} \sin \theta_i \end{align}\] <p>I implemented the code using Python 3, NumPy, SciPy, and Matplotlib and it is available as a Jupyter Notebook in this gist: <a href="https://gist.github.com/tlnagy/cba938ffd5c98236e90bfd1dc3d23d11">https://gist.github.com/tlnagy/cba938ffd5c98236e90bfd1dc3d23d11</a>. The students found a quite few parameter combinations that yielded interesting results, most of which were highly unrealistic. I suspect this is due to the much lower “concentration” of microtubules that we used in our simulation to achieve interactivity, $N=1500$ instead of $N=2621440$. We were still able to get vortices to form:</p> <p><img src="/assets/images/2017-09-07-microtubule-vortices/mt_initial.gif" alt="Initially, microtubule movement looks pretty random."/></p> <p><img src="/assets/images/2017-09-07-microtubule-vortices/mt_vortices.gif" alt="However, they start to coalesce into a grid of vortices"/></p> <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> <h2 id="references">References</h2>]]></content><author><name>Tamas Nagy</name></author><category term="science"/><category term="math"/><summary type="html"><![CDATA[Yesterday was the systems biology module of the iPQB bootcamp here at UCSF. I was in charge of the modeling section and I decided to try to get the students to model the relatively simple active matter system from @Sumino2012-dc since it was relatively straightforward, very visual, and shows complex emergent properties from simple rules (See Figure 1). Active matter systems are ubiquitous nonequilibrium condensed systems whose “unifying characteristic is that they are composed of self-driven units, active particles, each capable of converting stored or ambient free energy into systematic movement” [@Marchetti2013]. An in vitro microtubule and dynein system, like the one we’re investigating here, is much more controlled and reproducible compared to the flocking of birds or fish and thus serves as a nice model system in which to study active matter.]]></summary></entry><entry><title type="html">Copper Creek and Lower Paradise Valley Trip Report</title><link href="https://tlnagy.github.io/blog/2017/kings-canyon-trip-report/" rel="alternate" type="text/html" title="Copper Creek and Lower Paradise Valley Trip Report"/><published>2017-07-02T12:00:00+00:00</published><updated>2017-07-02T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2017/kings-canyon-trip-report</id><content type="html" xml:base="https://tlnagy.github.io/blog/2017/kings-canyon-trip-report/"><![CDATA[<blockquote> <p>Nature is ever at work building and pulling down, creating and destroying, keeping everything whirling and flowing, allowing no rest but in rhythmical motion, chasing everything in endless song out of one beautiful form into another.</p> <p>– John Muir in <a href="http://vault.sierraclub.org/john_muir_exhibit/writings/our_national_parks/chapter_3.aspx">Our National Parks, Chapter 3</a></p> </blockquote> <p>This has been a crazy year in the Sierras. We’ve had record snowfall and now everything is melting and <a href="http://www.latimes.com/local/lanow/la-me-ln-kings-river-flooding-snowpack-20170626-story.html">flooding like crazy</a>. The rivers are swollen and the falls are roaring so we thought we had to get out and experience it.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170625_134943.jpg" alt="The view from Lower Paradise Valley, Kings Canyon NP"/></p> <p>We left late last Friday night, June 23rd, at around 7pm from San Francisco. We picked up Alex and Leslie down in Burlingame and aimed the car towards the Sierras. The drive over to Kings Canyon was fairly uneventful. Traffic was light and the weather was good, but very hot in the Central Valley. As we gained altitude, the temps dropped to be a more reasonable 60s-70s, but it was also close to 12:30am at this point. All the campgrounds in Kings Canyon were full so we pitched our tents next to the road in Sequoia National Forest and went to sleep dreaming about the next day.</p> <p>It was slow going the next morning as Andrea and I were pretty tired, but Alex and Leslie were already up and ready to roll out. We still had a bit of driving to do, but what a drive it was. The 180 carves back and forth on the south side of the canyon with imposing granite monoliths on either side and the ferocious Kings River pummeling away at the rocks below. Wildflowers, in stark contrast with this savagery, were in full bloom, all decked out in their royal purples and pinks.</p> <p>We kept going, engine roaring away as we climbed. The road then passed over to the north side of the canyon and it dropped nearly to the level of the river. This is where you could really feel its raw power. The Kings held nothing back. The river was completely white with fury. Trees held on for dear life as the ground beneath them was swept away, but it was only a matter of time. The Kings River will win.</p> <p>The road, as if sensing that it should leave before it too was washed away, then curved away from the river. We passed through some beautiful evergreen forests and enjoyed the gentler incline. We were in the valley proper. We could see massive granite piles peaking out from between the trees and rising thousands of feet vertically from the valley floor. But then, abruptly, we ran out of asphalt. We had reached the road’s end.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170624_095843.jpg" alt="At Road's End"/></p> <p>We had wanted to do part of the Rae Lakes Loop in Kings Canyon National Park, but after talking to the rangers we learned that the recent snowmelt had wrecked havok on that area. Bridges were washed away, trails were flooded, and they had years worth of work to repair everything. We decided that we should hike the Copper Creek trail since it was one of the least affected by the flooding.</p> <p>We started up the trail around 10am. It was already in high 80s and sun was beating down on us. The trail starts off at a breakneck pace upwards climbing 1000+ feet a mile. The flora was very Mediterranean in nature and bone dry. It did not provide us with much cover from the sun, but thankfully the clouds rolled in and cooled us off with some light showers.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170624_135938.jpg" alt="Andrea and me; cloud worshippers"/></p> <p>The heat, altitude (close to 8000 feet at this point), and lack of sleep got to us. We set up camp close to Lower Tent Meadow about 4 miles in and took a nap. Alex and Leslie kept going, determined to reach Grouse Lake at 10,000 feet. We ended up relaxing most of the afternoon and making dinner before they came back. They turned back once they hit the snow line at 9500 feet. A ranger stopped by our campground and she said that a group further along the trail saw a mother bear and with some cubs and had to scare them off when they got too inquisitive.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170624_203101.jpg" alt="Not the flattest campground"/></p> <p>It was much cooler up here then down below so we slept much better. The next day, we decided to go back down to Road’s End and do a short day hike up to Mist Falls since the rest of the Copper Creek trail past Upper Tent Meadow was not passable yet. The hike down went very quickly and was fairly uneventful. A highlight was seeing a deer very close to the trail and the magnificent views that we would sometimes get between the trails.</p> <p>We dropped off some of our gear at the car and then headed out towards Mist Falls. It was about 4.7 miles from the trailhead, but the route was fairly flat. The challenge this time came in the form of flooding of the trail and loads of mosquitoes. The insects were unbearable in the wooded areas. They swarmed behind us and if we stopped, even for a couple seconds, we were quickly coated with them. We tried to keep up the pace the whole time. We also ran into quite a few snakes, including a juvenile rattler, likely ousted from their normal dwellings by the raging river.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170625_133449.jpg" alt="The Kings River showed no mercy and neither did the mosquitoes"/></p> <p>Once we made it out of the boggy parts of the trail, the landscape changed dramatically. Granite flows started to dominate and the mosquitoes wilted away. The forest opened up and we were greeted with some of the most picturesque views that I have ever experienced in the Sierras. We stretched out on the warm granite flows and soaked in the warm California sun while Mist Falls roared away behind us.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170625_134939.jpg" alt="This view is priceless"/></p> <p>We even saw a hummingbird investigating some flowers near us. Paradise Valley, indeed.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170625_135724.jpg" alt="Hummingbird in paradise"/></p> <p>We had to brave the bogs and mosquitoes on the way back too, but we were mentally prepared for it this time. We slogged through it again and made it back to car with only couple more bites to our name.</p>]]></content><author><name>Tamas Nagy</name></author><category term="trip report"/><summary type="html"><![CDATA[Nature is ever at work building and pulling down, creating and destroying, keeping everything whirling and flowing, allowing no rest but in rhythmical motion, chasing everything in endless song out of one beautiful form into another. – John Muir in Our National Parks, Chapter 3]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tlnagy.github.io/2017-07-02-kings-canyon-trip-report/IMG_20170625_134939.jpg"/><media:content medium="image" url="https://tlnagy.github.io/2017-07-02-kings-canyon-trip-report/IMG_20170625_134939.jpg" xmlns:media="http://search.yahoo.com/mrss/"/></entry><entry><title type="html">UCSF Graduate Student Taxes FAQ</title><link href="https://tlnagy.github.io/blog/2017/grad-student-taxes/" rel="alternate" type="text/html" title="UCSF Graduate Student Taxes FAQ"/><published>2017-05-31T12:00:00+00:00</published><updated>2017-05-31T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2017/grad-student-taxes</id><content type="html" xml:base="https://tlnagy.github.io/blog/2017/grad-student-taxes/"><![CDATA[<p>I’m currently a 2nd year graduate student in the quantitative biology program at UCSF. I am certainly no tax professional<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>, but I thought I would write a bit about what you can expect to pay in taxes at UCSF. These are some questions that I think I would have appreciated knowing the answers to in my first two years<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>.</p> <h3 id="do-we-have-to-pay-taxes">Do we have to pay taxes?</h3> <p>Yes, both state and federal. The tricky part is that while you are paid by UCSF on a 1098-T form (normally for your first two years) nothing is withheld for taxes so you have pay the full amount come April.</p> <h3 id="how-much-should-i-set-aside-each-month-for-taxes">How much should I set aside each month for taxes?</h3> <p>Most estimates are between $400-500 a month depending on your specific situation. I would probably aim for $425.</p> <p>Now assuming that you did not have any external income, you should expect to pay roughly $2000<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup> in your first year since you are only taxed for October, November, and December. 2nd year you have to pay for the entire year and this works out to being close to $4800. It’s a lot if you’re not ready for it.</p> <h3 id="how-much-do-i-actually-owe">How much do I actually owe?</h3> <p>In the simplest case, your “taxable income” is simply the difference between box 5 and box 1 on your 1098-T form. This value will be higher than your stipend since it includes the “taxable” contributions to our health insurance, UC SHIP. You can find your 1098-T at <a href="https://1098t.com">https://1098t.com</a>.</p> <h3 id="how-do-i-e-file-for-free">How do I e-file for free?</h3> <p>There is no need to pay for e-filing since we make less than the limit for <a href="https://apps.irs.gov/app/freeFile/jsp/wizard.jsp?">IRS FreeFile</a>. Just fill out the form and select one of the free filing options. I have had good luck with TaxAct.</p> <h3 id="can-we-withhold-taxes-so-that-april-isnt-such-a-bummer">Can we withhold taxes so that April isn’t such a bummer?</h3> <p>Yes. In my opinion, the easiest and best way to do this to <a href="https://www.irs.gov/uac/pay-taxes-by-electronic-funds-withdrawal">set up estimated tax payments</a> when you e-file. Your bank account is debited according to whatever estimated tax plan you submit. This is also nice because you do not have to pay the penalty for failing to withhold income<sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup>. Make sure to set up payments to both the IRS and California’s Franchise Tax Board. This should be quite easy if you are setting this up during e-filing.</p> <h3 id="can-we-contribute-to-a-roth-ira">Can we contribute to a Roth IRA?</h3> <p>Unfortunately, to the best of my knowledge, we cannot. Since the money we make on a 1098-T is considered taxable, unearned income it does not qualify for IRA. According to <a href="https://www.irs.gov/pub/irs-pdf/p590a.pdf">IRS Pub 590-A</a> (Page 6):</p> <blockquote> <p>Scholarship and fellowship payments are compensation for IRA purposes only if shown in box 1 of Form W-2</p> </blockquote> <p>However, the moment you are switched to a W-2, you can contribute up to your earned income amount or $5500, which ever is smaller.</p> <h3 id="what-is-a-roth-ira">What is a Roth IRA?</h3> <p>They are super cool, read more about them <a href="https://www.bogleheads.org/wiki/Roth_IRA">here</a>. Basically, they are a great way to save for retirement as a graduate student. Since we are in a very low tax bracket, you pay our low marginal tax rate now for the money you put in and all future earnings are tax-free for retirement.</p> <h3 id="but-what-if-i-want-to-save-for-more-immediate-things-than-retirement">But what if I want to save for more immediate things than retirement?</h3> <p>Roths can still help you. You can always take the principal (the original money you contributed, not the earnings) out tax-free since you already paid taxes on it. Now I don’t recommend this since you can’t put that money back later due to the annual cap of $5500. But in an emergency, you can access the principal. Also, there are exceptions for removing earnings from a Roth without paying the penalty like substantial medical bills, first-time home purchase, etc. You have to be more careful with the rules here, see <a href="http://www.rothira.com/roth-ira-withdrawal-rules">this</a> for more details.</p> <p>club. Thanks Kyle! Update: After I wrote this piece, I found out that Kyle also had a blog post about this a couple years ago: <a href="https://www.kylebarlow.com/dearth-and-taxes.html">https://www.kylebarlow.com/dearth-and-taxes.html</a></p> <p>increases. For reference, in my first two years, we made 34K (TY2015) and then 36K (TY2016).</p> <p>is based on the previous tax year. It will be quite large in your 3rd year if you don’t set up an estimated tax payment.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>So YMMV on all this depending on your specific circumstances <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>This post was inspired by a presentation by Kyle Barlow at iPQB journal <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>Naturally, this value will increase if the UCSF graduate student stipend <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:4"> <p>This penalty was pretty small for me as a 1st and 2nd year because it <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Tamas Nagy</name></author><category term="random"/><summary type="html"><![CDATA[I’m currently a 2nd year graduate student in the quantitative biology program at UCSF. I am certainly no tax professional1, but I thought I would write a bit about what you can expect to pay in taxes at UCSF. These are some questions that I think I would have appreciated knowing the answers to in my first two years2. So YMMV on all this depending on your specific circumstances &#8617; This post was inspired by a presentation by Kyle Barlow at iPQB journal &#8617;]]></summary></entry><entry><title type="html">Embedding videos in Google Slides as GIFs</title><link href="https://tlnagy.github.io/blog/2016/videos-in-google-slides-gifs/" rel="alternate" type="text/html" title="Embedding videos in Google Slides as GIFs"/><published>2016-08-15T12:00:00+00:00</published><updated>2016-08-15T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2016/videos-in-google-slides-gifs</id><content type="html" xml:base="https://tlnagy.github.io/blog/2016/videos-in-google-slides-gifs/"><![CDATA[<p>In my field, systems biology, it’s pretty common to take time-lapse movies to get the dynamics of how the system behaves. And we like showing them off. This makes Google Slides<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> inability to embed videos (without uploading them to Youtube) pretty annoying and inconvenient. Slides does, on the other hand, have good support for embedding GIFs. I came up with the following pipeline (based on notedible’s comment on <a href="https://superuser.com/questions/556029/how-do-i-convert-a-video-to-gif-using-ffmpeg-with-reasonable-quality">Stackoverflow</a>). First, make sure to install <code class="language-plaintext highlighter-rouge">libav</code> and <code class="language-plaintext highlighter-rouge">imagemagick</code>. On Debian-based systems, you can run</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt-get install libav-tools imagemagick
</code></pre></div></div> <p>and on MacOS<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> the easiest way to install them is via <a href="http://brew.sh">homebrew</a>. Then I use the following command to create the GIF:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat some_movie.m4v | avconv -i pipe: -r 10 -f image2pipe -vcodec ppm - | convert -delay 5 -loop 0 - gif:- | convert -layers Optimize - output.gif
</code></pre></div></div> <p>where <code class="language-plaintext highlighter-rouge">some_movie.m4v</code> is the video file. This creates an optimized GIF version called <code class="language-plaintext highlighter-rouge">output.gif</code>, which you can then upload to Google Slides. The last niggle is that the GIFs play continuously and sometimes it’s helpful to be able to stop/start the playback. Enter the <a href="https://addons.mozilla.org/en-US/firefox/addon/toggle-animated-gifs/">Toggle Animated Gifs</a> extension for Firefox (I’m sure there’s something comparable for Chrome), which lets you do just that.</p> <h2 id="addendum-17-04-28">Addendum 17-04-28</h2> <p>If you get an error that looks like the following with some weirdly formatted <code class="language-plaintext highlighter-rouge">.mov</code> files:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>avconv version 12, Copyright (c) 2000-2016 the Libav developers
  built on Mar  6 2017 22:35:59 with Apple LLVM version 8.0.0 (clang-800.0.42.1)
[mov,mp4,m4a,3gp,3g2,mj2 @ 0x7fc78b000000] stream 0, offset 0x30: partial file
[mov,mp4,m4a,3gp,3g2,mj2 @ 0x7fc78b000000] Could not find codec parameters (Video: mpeg4 (Simple Profile) [mp4v / 0x7634706D]
      none, 1958 kb/s)
Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'pipe:':
  Metadata:
    major_brand     : qt
    minor_version   : 537199360
    compatible_brands: qt
    creation_time   : 2015-05-26 19:04:15
  Duration: 00:00:10.00, bitrate: N/A
    Stream #0:0(eng): Video: mpeg4 (Simple Profile) [mp4v / 0x7634706D]
      none, 1958 kb/s
      600 tbn (default)
    Metadata:
      creation_time   : 2015-05-26 19:04:15
      handler_name    : Apple Alias Data Handler
      encoder         : MPEG-4 Video
Output #0, image2pipe, to 'pipe:':
Output file #0 does not contain any stream
convert: no decode delegate for this image format `' @ error/constitute.c/ReadImage/509.
convert: no images defined `gif:-' @ error/convert.c/ConvertImageCommand/3254.
convert: no decode delegate for this image format `' @ error/constitute.c/ReadImage/509.
convert: no images defined `output.gif' @
error/convert.c/ConvertImageCommand/3254. 
</code></pre></div></div> <p>Then installing the <code class="language-plaintext highlighter-rouge">qtfaststart</code><sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup> Python package via <code class="language-plaintext highlighter-rouge">pip install qtfaststart</code> and then running</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>qtfaststart bad_movie.mov good_movie.mov
</code></pre></div></div> <p>should fix the problem and now you can use <code class="language-plaintext highlighter-rouge">good_movie.mov</code> with the previous commands to create all the gifs. So <a href="https://superuser.com/questions/479063/ffmpeg-pipe-input-error/479064#479064">apparently</a> what is happening is that some recording software puts the <code class="language-plaintext highlighter-rouge">mdat</code> block prior to the <code class="language-plaintext highlighter-rouge">moov</code> block (the structural metadata). This is more convenient for recording since the structure isn’t known till the recording is finished, however for playback it isn’t as nice. <code class="language-plaintext highlighter-rouge">qtfaststart</code> fixes this by swapping the two blocks:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ qtfaststart -l bad_movie.mov
ftyp (32 bytes)
wide (8 bytes)
mdat (2448358 bytes)
moov (998 bytes)
</code></pre></div></div> <p>while</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>qtfaststart -l good_movie.mov
ftyp (32 bytes)
moov (998 bytes)
wide (8 bytes)
mdat (2448358 bytes)
</code></pre></div></div> <p>its simplicity, portability, and collaboration features. Hard to beat for presentations.</p> <p>qtfaststart.c file. Why ffmpeg can’t do this on its own? Who knows.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>I like Google Slides for a variety of reasons, but the main ones are <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>OS X dammit <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>So apparently this Python package just repackages ffmpeg’s own <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Tamas Nagy</name></author><category term="science"/><category term="productivity"/><summary type="html"><![CDATA[In my field, systems biology, it’s pretty common to take time-lapse movies to get the dynamics of how the system behaves. And we like showing them off. This makes Google Slides1 inability to embed videos (without uploading them to Youtube) pretty annoying and inconvenient. Slides does, on the other hand, have good support for embedding GIFs. I came up with the following pipeline (based on notedible’s comment on Stackoverflow). First, make sure to install libav and imagemagick. On Debian-based systems, you can run I like Google Slides for a variety of reasons, but the main ones are &#8617;]]></summary></entry><entry><title type="html">Precision-Recall curves in Julia</title><link href="https://tlnagy.github.io/blog/2016/precision-recall-julia/" rel="alternate" type="text/html" title="Precision-Recall curves in Julia"/><published>2016-05-31T12:00:00+00:00</published><updated>2016-05-31T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2016/precision-recall-julia</id><content type="html" xml:base="https://tlnagy.github.io/blog/2016/precision-recall-julia/"><![CDATA[<p>Precision-Recall (PR) curves are useful for evaluating the performance of a binary classifier on highly skewed datasets where one class is much more prevalent than the other. This situation is common in biology where most things have little to no effect and there is a small subset of things that have large effect. In contrast to ROC curves, PR curves do not overestimate performance in these cases [@davis_relationship_2006]. The reason ROC curves are more sensitive to this issue is due to their reliance on the false positive rate (FPR), defined as $\frac{FP}{FP + TN}$ where $FP$ and $TN$ are the number of false positives and true negatives, respectively. Since $TN » FP$ for skewed datasets, ROC curves are insensitive to the number of false positives, making them overly optimistic.</p> <p>PR curves, on the other hand, do not use $TN$ so they avoid this problem, since precision and recall are defined as $\frac{TP}{TP+FP}$ and $\frac{TP}{TP+FN}$, respectively. Intuitively, precision measures what fraction of called positive hits are correct and recall measures how many of the actual positive hits did the algorithm call. Generating the curves is all very nice, but it is desirable to collapse this curve down into a single value when scanning through a large parameter space, which is often the area under the curve (AUC). However, unlike with ROC curves, there isn’t a single accepted way of computing the AUC of a PR curve (AUPRC).</p> <p>I recently found an interesting paper by @boyd_area_2013 that explored different ways of computing the AUPRC. They showed that there are some good and some very bad ways of computing this value and they generated some really nice figures in <code class="language-plaintext highlighter-rouge">R</code>. I much prefer <a href="http://julialang.org">Julia</a> so I decided to recreate some of the results of the paper using it. My implementation is pretty fast, but I would gladly accept any PRs to improve it.</p> <h2 id="precision-recall-and-auc-calculation">Precision, recall, and AUC calculation</h2> <figure class="highlight"><pre><code class="language-julia" data-lang="julia"> 
<span class="s">"""
Copyright 2016 Tamas Nagy, Martin Kampmann, and contributers

Licensed under the Apache License, Version 2.0 (the "</span><span class="n">License</span><span class="s">"); you may
not use this file except in compliance with the License. You may obtain a
copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "</span><span class="n">AS</span> <span class="n">IS</span><span class="s">" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
implied. See the License for the specific language governing
permissions and limitations under the License.
"""</span>

<span class="k">function</span><span class="nf"> Base.count</span><span class="x">(</span><span class="n">labels</span><span class="o">::</span><span class="kt">AbstractArray</span><span class="x">{</span><span class="kt">Symbol</span><span class="x">},</span> <span class="n">pos_labels</span><span class="o">::</span><span class="kt">Set</span><span class="x">{</span><span class="kt">Symbol</span><span class="x">})</span>
    <span class="n">num_pos</span><span class="x">,</span> <span class="n">num_neg</span> <span class="o">=</span> <span class="mi">0</span><span class="x">,</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">label</span> <span class="k">in</span> <span class="n">labels</span>
        <span class="k">if</span> <span class="n">label</span> <span class="k">in</span> <span class="n">pos_labels</span>
            <span class="n">num_pos</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span>
            <span class="n">num_neg</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">end</span>
    <span class="k">end</span>
    <span class="n">num_pos</span><span class="x">,</span> <span class="n">num_neg</span>
<span class="k">end</span>

<span class="s">"""
auprc(scores::AbstractArray{Float64}, classes::AbstractArray{Symbol}, pos_labels::Set{Symbol})

Computes the area under the Precision-Recall curve using a lower
trapezoidal estimator, which is more accurate for skewed datasets.
"""</span>
<span class="k">function</span><span class="nf"> auprc</span><span class="x">(</span><span class="n">scores</span><span class="o">::</span><span class="kt">AbstractArray</span><span class="x">{</span><span class="kt">Float64</span><span class="x">},</span> <span class="n">classes</span><span class="o">::</span><span class="kt">AbstractArray</span><span class="x">{</span><span class="kt">Symbol</span><span class="x">},</span> <span class="n">pos_labels</span><span class="o">::</span><span class="kt">Set</span><span class="x">{</span><span class="kt">Symbol</span><span class="x">})</span>
    <span class="n">num_scores</span> <span class="o">=</span> <span class="n">length</span><span class="x">(</span><span class="n">scores</span><span class="x">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">ordering</span> <span class="o">=</span> <span class="n">sortperm</span><span class="x">(</span><span class="n">scores</span><span class="x">,</span> <span class="n">rev</span><span class="o">=</span><span class="nb">true</span><span class="x">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">classes</span><span class="x">[</span><span class="n">ordering</span><span class="x">]</span>
    <span class="n">num_pos</span><span class="x">,</span> <span class="n">num_neg</span> <span class="o">=</span> <span class="n">count</span><span class="x">(</span><span class="n">labels</span><span class="x">,</span> <span class="n">pos_labels</span><span class="x">)</span>

    <span class="n">tn</span><span class="x">,</span> <span class="n">fn</span><span class="x">,</span> <span class="n">tp</span><span class="x">,</span> <span class="n">fp</span> <span class="o">=</span> <span class="mi">0</span><span class="x">,</span> <span class="mi">0</span><span class="x">,</span> <span class="n">num_pos</span><span class="x">,</span> <span class="n">num_neg</span>

    <span class="n">p</span> <span class="o">=</span> <span class="kt">Array</span><span class="x">(</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">num_scores</span><span class="x">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="kt">Array</span><span class="x">(</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">num_scores</span><span class="x">)</span>
    <span class="n">p</span><span class="x">[</span><span class="n">num_scores</span><span class="x">]</span> <span class="o">=</span> <span class="n">tp</span><span class="o">/</span><span class="x">(</span><span class="n">tp</span><span class="o">+</span><span class="n">fp</span><span class="x">)</span>
    <span class="n">r</span><span class="x">[</span><span class="n">num_scores</span><span class="x">]</span> <span class="o">=</span> <span class="n">tp</span><span class="o">/</span><span class="x">(</span><span class="n">tp</span><span class="o">+</span><span class="n">fn</span><span class="x">)</span>
    <span class="n">auprc</span><span class="x">,</span> <span class="n">prev_r</span> <span class="o">=</span> <span class="mf">0.0</span><span class="x">,</span> <span class="n">r</span><span class="x">[</span><span class="n">num_scores</span><span class="x">]</span>
    <span class="n">pmin</span><span class="x">,</span> <span class="n">pmax</span> <span class="o">=</span> <span class="n">p</span><span class="x">[</span><span class="n">num_scores</span><span class="x">],</span> <span class="n">p</span><span class="x">[</span><span class="n">num_scores</span><span class="x">]</span>

    <span class="c"># traverse scores from lowest to highest</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">num_scores</span><span class="o">-</span><span class="mi">1</span><span class="o">:-</span><span class="mi">1</span><span class="o">:</span><span class="mi">1</span>
        <span class="n">dtn</span> <span class="o">=</span> <span class="n">labels</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="k">in</span> <span class="n">pos_labels</span> <span class="o">?</span> <span class="mi">0</span> <span class="o">:</span> <span class="mi">1</span>
        <span class="n">tn</span> <span class="o">+=</span> <span class="n">dtn</span>
        <span class="n">fn</span> <span class="o">+=</span> <span class="mi">1</span><span class="o">-</span><span class="n">dtn</span>
        <span class="n">tp</span> <span class="o">=</span> <span class="n">num_pos</span> <span class="o">-</span> <span class="n">fn</span>
        <span class="n">fp</span> <span class="o">=</span> <span class="n">num_neg</span> <span class="o">-</span> <span class="n">tn</span>
        <span class="n">p</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">=</span> <span class="x">(</span><span class="n">tp</span><span class="o">+</span><span class="n">fp</span><span class="x">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">?</span> <span class="mi">1</span><span class="o">-</span><span class="n">dtn</span> <span class="o">:</span> <span class="n">tp</span><span class="o">/</span><span class="x">(</span><span class="n">tp</span><span class="o">+</span><span class="n">fp</span><span class="x">)</span>
        <span class="n">r</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">=</span> <span class="n">tp</span><span class="o">/</span><span class="x">(</span><span class="n">tp</span><span class="o">+</span><span class="n">fn</span><span class="x">)</span>

        <span class="c"># update max precision observed for current recall value</span>
        <span class="k">if</span> <span class="n">r</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">==</span> <span class="n">prev_r</span>
            <span class="n">pmax</span> <span class="o">=</span> <span class="n">p</span><span class="x">[</span><span class="n">i</span><span class="x">]</span>
        <span class="k">else</span>
            <span class="n">pmin</span> <span class="o">=</span> <span class="n">p</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="c"># min precision is always at recall switch</span>
            <span class="n">auprc</span> <span class="o">+=</span> <span class="x">(</span><span class="n">pmin</span> <span class="o">+</span> <span class="n">pmax</span><span class="x">)</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="x">(</span><span class="n">prev_r</span> <span class="o">-</span> <span class="n">r</span><span class="x">[</span><span class="n">i</span><span class="x">])</span>
            <span class="n">prev_r</span> <span class="o">=</span> <span class="n">r</span><span class="x">[</span><span class="n">i</span><span class="x">]</span>
            <span class="n">pmax</span> <span class="o">=</span> <span class="n">p</span><span class="x">[</span><span class="n">i</span><span class="x">]</span>
        <span class="k">end</span>
    <span class="k">end</span>
    <span class="n">auprc</span><span class="x">,</span> <span class="n">p</span><span class="x">,</span> <span class="n">r</span>
<span class="k">end</span></code></pre></figure> <p>##Plotting</p> <p>Then to recreate Figure 2:</p> <figure class="highlight"><pre><code class="language-julia" data-lang="julia"><span class="k">using</span> <span class="n">Distributions</span>
<span class="k">using</span> <span class="n">Gadfly</span>
<span class="nb">π</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">test_dists</span> <span class="o">=</span> <span class="kt">Array</span><span class="x">[</span>
    <span class="x">[</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mi">1</span><span class="x">),</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">1</span><span class="x">,</span><span class="mi">1</span><span class="x">)],</span>
    <span class="x">[</span><span class="n">Beta</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">5</span><span class="x">),</span> <span class="n">Beta</span><span class="x">(</span><span class="mi">5</span><span class="x">,</span> <span class="mi">2</span><span class="x">)],</span>
    <span class="x">[</span><span class="n">Uniform</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mi">1</span><span class="x">),</span> <span class="n">Uniform</span><span class="x">(</span><span class="mf">0.5</span><span class="x">,</span> <span class="mf">1.5</span><span class="x">)]</span>
<span class="x">]</span>
<span class="n">x_ranges</span> <span class="o">=</span> <span class="kt">Array</span><span class="x">[</span>
    <span class="n">linspace</span><span class="x">(</span><span class="o">-</span><span class="mi">5</span><span class="x">,</span> <span class="mi">5</span><span class="x">,</span> <span class="mi">500</span><span class="x">),</span>
    <span class="n">linspace</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mi">1</span><span class="x">,</span> <span class="mi">500</span><span class="x">),</span>
    <span class="n">linspace</span><span class="x">(</span><span class="o">-</span><span class="mf">0.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">,</span> <span class="mi">500</span><span class="x">)</span>
<span class="x">]</span>


<span class="n">names</span> <span class="o">=</span> <span class="x">[</span><span class="s">"binormal"</span><span class="x">,</span> <span class="s">"bibeta"</span><span class="x">,</span> <span class="s">"offset uniform"</span><span class="x">]</span>

<span class="n">plots</span> <span class="o">=</span> <span class="x">[]</span>
<span class="k">for</span> <span class="x">(</span><span class="n">name</span><span class="x">,</span> <span class="n">test_dist</span><span class="x">,</span> <span class="n">xs</span><span class="x">)</span> <span class="k">in</span> <span class="n">zip</span><span class="x">(</span><span class="n">names</span><span class="x">,</span> <span class="n">test_dists</span><span class="x">,</span> <span class="n">x_ranges</span><span class="x">)</span>
    <span class="n">X</span><span class="x">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">test_dist</span>
    <span class="n">push!</span><span class="x">(</span><span class="n">plots</span><span class="x">,</span> <span class="n">plot</span><span class="x">(</span>
        <span class="n">layer</span><span class="x">(</span><span class="n">x</span><span class="o">=</span><span class="n">xs</span><span class="x">,</span> <span class="n">y</span><span class="o">=</span><span class="n">pdf</span><span class="x">(</span><span class="n">X</span><span class="x">,</span> <span class="n">xs</span><span class="x">),</span> <span class="n">Geom</span><span class="o">.</span><span class="n">line</span><span class="x">,</span> <span class="n">Theme</span><span class="x">(</span><span class="n">line_width</span><span class="o">=</span><span class="mi">2</span><span class="n">pt</span><span class="x">,</span> <span class="n">default_color</span><span class="o">=</span><span class="n">colorant</span><span class="s">"#cccccc"</span><span class="x">)),</span>
        <span class="n">layer</span><span class="x">(</span><span class="n">x</span><span class="o">=</span><span class="n">xs</span><span class="x">,</span> <span class="n">y</span><span class="o">=</span><span class="n">pdf</span><span class="x">(</span><span class="n">Y</span><span class="x">,</span> <span class="n">xs</span><span class="x">),</span> <span class="n">Geom</span><span class="o">.</span><span class="n">line</span><span class="x">),</span>
    <span class="n">Guide</span><span class="o">.</span><span class="n">ylabel</span><span class="x">(</span><span class="s">""</span><span class="x">),</span> <span class="n">Guide</span><span class="o">.</span><span class="n">xlabel</span><span class="x">(</span><span class="s">""</span><span class="x">),</span> <span class="n">Guide</span><span class="o">.</span><span class="n">title</span><span class="x">(</span><span class="n">name</span><span class="x">),</span> <span class="n">Guide</span><span class="o">.</span><span class="n">yticks</span><span class="x">()</span>
    <span class="x">))</span>
<span class="k">end</span>
<span class="n">draw</span><span class="x">(</span><span class="n">SVG</span><span class="x">(</span><span class="mi">30</span><span class="n">cm</span><span class="x">,</span> <span class="mi">10</span><span class="n">cm</span><span class="x">),</span> <span class="n">hstack</span><span class="x">(</span><span class="n">plots</span><span class="o">...</span><span class="x">))</span></code></pre></figure> <p><img src="/assets/images/pr-dists.svg" alt="The artificial datasets with the positive distributions in blue and the negative ones in grey"/></p> <p>And now we’re ready for Figure 3:</p> <figure class="highlight"><pre><code class="language-julia" data-lang="julia"><span class="c"># true precision, recall functions</span>
<span class="n">recall</span><span class="x">(</span><span class="n">xs</span><span class="x">,</span> <span class="n">Y</span><span class="x">)</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">cdf</span><span class="x">(</span><span class="n">Y</span><span class="x">,</span> <span class="n">xs</span><span class="x">)</span>
<span class="n">precision</span><span class="x">(</span><span class="n">xs</span><span class="x">,</span> <span class="nb">π</span><span class="x">,</span> <span class="n">X</span><span class="x">,</span> <span class="n">Y</span><span class="x">)</span> <span class="o">=</span> <span class="nb">π</span><span class="o">*</span><span class="n">recall</span><span class="x">(</span><span class="n">xs</span><span class="x">,</span> <span class="n">Y</span><span class="x">)</span><span class="o">./</span><span class="x">(</span><span class="nb">π</span><span class="o">*</span><span class="n">recall</span><span class="x">(</span><span class="n">xs</span><span class="x">,</span> <span class="n">Y</span><span class="x">)</span> <span class="o">+</span> <span class="x">(</span><span class="mi">1</span><span class="o">-</span><span class="nb">π</span><span class="x">)</span><span class="o">*</span><span class="x">(</span><span class="mi">1</span><span class="o">-</span><span class="n">cdf</span><span class="x">(</span><span class="n">X</span><span class="x">,</span> <span class="n">xs</span><span class="x">)))</span>


<span class="n">plots</span> <span class="o">=</span> <span class="n">Plot</span><span class="x">[]</span>
<span class="k">for</span> <span class="x">(</span><span class="n">name</span><span class="x">,</span> <span class="n">dists</span><span class="x">,</span> <span class="n">xs</span><span class="x">)</span> <span class="k">in</span> <span class="n">zip</span><span class="x">(</span><span class="n">names</span><span class="x">,</span> <span class="n">test_dists</span><span class="x">,</span> <span class="n">x_ranges</span><span class="x">)</span>
    <span class="n">X</span><span class="x">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">dists</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="x">[</span><span class="o">:</span><span class="n">b</span><span class="x">,</span> <span class="o">:</span><span class="n">a</span><span class="x">]</span>

    <span class="n">layers</span> <span class="o">=</span> <span class="x">[]</span>
    <span class="n">push!</span><span class="x">(</span><span class="n">layers</span><span class="x">,</span> <span class="n">layer</span><span class="x">(</span><span class="n">x</span><span class="o">=</span><span class="n">recall</span><span class="x">(</span><span class="n">xs</span><span class="x">,</span> <span class="n">Y</span><span class="x">),</span> <span class="n">y</span><span class="o">=</span><span class="n">precision</span><span class="x">(</span><span class="n">xs</span><span class="x">,</span> <span class="nb">π</span><span class="x">,</span> <span class="n">X</span><span class="x">,</span> <span class="n">Y</span><span class="x">),</span> 
    <span class="n">Geom</span><span class="o">.</span><span class="n">line</span><span class="x">,</span> <span class="n">Theme</span><span class="x">(</span><span class="n">line_width</span><span class="o">=</span><span class="mi">2</span><span class="n">pt</span><span class="x">)))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="mi">10</span>
        <span class="n">cat</span> <span class="o">=</span> <span class="n">rand</span><span class="x">(</span><span class="n">Categorical</span><span class="x">([</span><span class="mi">1</span><span class="o">-</span><span class="nb">π</span><span class="x">,</span> <span class="nb">π</span><span class="x">]),</span> <span class="mi">500</span><span class="x">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">map</span><span class="x">(</span><span class="n">rand</span><span class="x">,</span> <span class="n">dists</span><span class="x">[</span><span class="n">cat</span><span class="x">])</span>    
        <span class="n">_auprc</span><span class="x">,</span> <span class="n">p</span><span class="x">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">auprc</span><span class="x">(</span><span class="n">scores</span><span class="x">,</span> <span class="n">classes</span><span class="x">[</span><span class="n">cat</span><span class="x">],</span> <span class="kt">Set</span><span class="x">([</span><span class="o">:</span><span class="n">a</span><span class="x">]))</span>
        <span class="n">push!</span><span class="x">(</span><span class="n">layers</span><span class="x">,</span> <span class="n">layer</span><span class="x">(</span><span class="n">x</span><span class="o">=</span><span class="n">r</span><span class="x">,</span> <span class="n">y</span><span class="o">=</span><span class="n">p</span><span class="x">,</span><span class="n">Geom</span><span class="o">.</span><span class="n">line</span><span class="x">,</span> 
        <span class="n">Theme</span><span class="x">(</span><span class="n">default_color</span><span class="o">=</span><span class="n">colorant</span><span class="s">"#cccccc"</span><span class="x">,</span> <span class="n">highlight_width</span><span class="o">=</span><span class="mi">0</span><span class="n">pt</span><span class="x">)))</span>
    <span class="k">end</span>
    <span class="n">push!</span><span class="x">(</span><span class="n">plots</span><span class="x">,</span> <span class="n">plot</span><span class="x">(</span><span class="n">layers</span><span class="o">...</span><span class="x">,</span> <span class="n">Coord</span><span class="o">.</span><span class="n">cartesian</span><span class="x">(</span><span class="n">fixed</span><span class="o">=</span><span class="nb">true</span><span class="x">),</span> 
    <span class="n">Guide</span><span class="o">.</span><span class="n">ylabel</span><span class="x">(</span><span class="s">"precision"</span><span class="x">),</span> <span class="n">Guide</span><span class="o">.</span><span class="n">xlabel</span><span class="x">(</span><span class="s">"recall"</span><span class="x">),</span>
    <span class="n">Guide</span><span class="o">.</span><span class="n">title</span><span class="x">(</span><span class="n">name</span><span class="x">),</span> <span class="n">Guide</span><span class="o">.</span><span class="n">yticks</span><span class="x">(</span><span class="n">ticks</span><span class="o">=</span><span class="x">[</span><span class="mf">0.0</span><span class="x">,</span> <span class="mf">0.5</span><span class="x">,</span> <span class="mf">1.0</span><span class="x">])))</span>
<span class="k">end</span>
<span class="n">draw</span><span class="x">(</span><span class="n">SVG</span><span class="x">(</span><span class="mi">30</span><span class="n">cm</span><span class="x">,</span> <span class="mi">10</span><span class="n">cm</span><span class="x">),</span> <span class="n">hstack</span><span class="x">(</span><span class="n">plots</span><span class="x">))</span></code></pre></figure> <p>Voila, we have Figure 3:</p> <p><img src="/assets/images/precision-recall.svg" alt="Precision-recall curves on highly skewed artificial datasets. 90% of the data is negative."/></p> <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> <h2 id="references">References</h2>]]></content><author><name>Tamas Nagy</name></author><category term="julia"/><category term="science"/><summary type="html"><![CDATA[Precision-Recall (PR) curves are useful for evaluating the performance of a binary classifier on highly skewed datasets where one class is much more prevalent than the other. This situation is common in biology where most things have little to no effect and there is a small subset of things that have large effect. In contrast to ROC curves, PR curves do not overestimate performance in these cases [@davis_relationship_2006]. The reason ROC curves are more sensitive to this issue is due to their reliance on the false positive rate (FPR), defined as $\frac{FP}{FP + TN}$ where $FP$ and $TN$ are the number of false positives and true negatives, respectively. Since $TN » FP$ for skewed datasets, ROC curves are insensitive to the number of false positives, making them overly optimistic.]]></summary></entry><entry><title type="html">Native MTP interconnect on Mac/Linux</title><link href="https://tlnagy.github.io/blog/2016/mtp-interconnect-mac-linux/" rel="alternate" type="text/html" title="Native MTP interconnect on Mac/Linux"/><published>2016-02-17T12:00:00+00:00</published><updated>2016-02-17T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2016/mtp-interconnect-mac-linux</id><content type="html" xml:base="https://tlnagy.github.io/blog/2016/mtp-interconnect-mac-linux/"><![CDATA[<p>Connecting your phone to your computer via MTP isn’t as easy as it should be: the Android File Transfer app is very lackluster and I wanted to have native file manager integration so that my phone would show up in either Nautilus on Debian or Finder on Mac. Here’s how I got it working.</p> <h2 id="linux-setup">Linux setup</h2> <p>On Debian (or Debian derivatives like Ubuntu):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt-get install libfuse-dev android-tools-adb
</code></pre></div></div> <h2 id="mac-setup">Mac setup</h2> <p>Install Homebrew (<a href="http://brew.sh">http://brew.sh</a>) and OSXFuse (<a href="https://osxfuse.github.io/">https://osxfuse.github.io/</a>) then run:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew update
brew install android-platform-tools
</code></pre></div></div> <h2 id="clone-build-and-setup-adbfs">Clone, build, and setup <code class="language-plaintext highlighter-rouge">adbfs</code></h2> <p>We’ll be using <a href="https://github.com/spion/adbfs-rootless"><code class="language-plaintext highlighter-rouge">adbfs</code></a> to mount our Android phone:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone git://github.com/spion/adbfs-rootless.git
cd adbfs-rootless    
make
</code></pre></div></div> <p>Create a mount point</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mkdir ~/phone
</code></pre></div></div> <p>Mount device as follows:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./adbfs ~/phone
</code></pre></div></div> <p>And your phone should be mounted and visible the same way as any DAS device (e.g. External drives).</p> <h2 id="troubleshooting">Troubleshooting</h2> <p>Try reseting and restarting <code class="language-plaintext highlighter-rouge">adb</code> and the mount point</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>killall -9 adb; sudo umount -f ~/phone
</code></pre></div></div>]]></content><author><name>Tamas Nagy</name></author><category term="linux"/><category term="mac"/><category term="android"/><category term="diy"/><summary type="html"><![CDATA[Connecting your phone to your computer via MTP isn’t as easy as it should be: the Android File Transfer app is very lackluster and I wanted to have native file manager integration so that my phone would show up in either Nautilus on Debian or Finder on Mac. Here’s how I got it working.]]></summary></entry></feed>