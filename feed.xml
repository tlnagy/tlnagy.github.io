<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://tlnagy.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://tlnagy.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-11-05T01:06:55+00:00</updated><id>https://tlnagy.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://tlnagy.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://tlnagy.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[<p>May 14, 2024 We‚Äôre introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants. In December, we launched our first natively multimodal model Gemini 1.0 in three sizes: Ultra, Pro and Nano. Just a few months later we released 1.5 Pro, with enhanced performance and a breakthrough long context window of 1 million tokens.Developers and enterprise customers have been putting 1.5 Pro to use in incredible ways and finding its long context window, multimodal reasoning capabilities and impressive overall performance incredibly useful.We know from user feedback that some applications need lower latency and a lower cost to serve. This inspired us to keep innovating, so today, we‚Äôre introducing Gemini 1.5 Flash: a model that‚Äôs lighter-weight than 1.5 Pro, and designed to be fast and efficient to serve at scale.Both 1.5 Pro and 1.5 Flash are available in public preview with a 1 million token context window in Google AI Studio and Vertex AI. And now, 1.5 Pro is also available with a 2 million token context window via waitlist to developers using the API and to Google Cloud customers.We‚Äôre also introducing updates across the Gemini family of models, announcing our next generation of open models, Gemma 2, and sharing progress on the future of AI assistants, with Project Astra.Context lengths of leading foundation models compared with Gemini 1.5‚Äôs 2 million token capability1.5 Flash is the newest addition to the Gemini model family and the fastest Gemini model served in the API. It‚Äôs optimized for high-volume, high-frequency tasks at scale, is more cost-efficient to serve and features our breakthrough long context window.While it‚Äôs a lighter weight model than 1.5 Pro, it‚Äôs highly capable of multimodal reasoning across vast amounts of information and delivers impressive quality for its size.The new Gemini 1.5 Flash model is optimized for speed and efficiency, is highly capable of multimodal reasoning and features our breakthrough long context window.1.5 Flash excels at summarization, chat applications, image and video captioning, data extraction from long documents and tables, and more. This is because it‚Äôs been trained by 1.5 Pro through a process called ‚Äúdistillation,‚Äù where the most essential knowledge and skills from a larger model are transferred to a smaller, more efficient model.Read more about 1.5 Flash in our updated Gemini 1.5 technical report, on the Gemini technology page, and learn about 1.5 Flash‚Äôs availability and pricing.Over the last few months, we‚Äôve significantly improved 1.5 Pro, our best model for general performance across a wide range of tasks.Beyond extending its context window to 2 million tokens, we‚Äôve enhanced its code generation, logical reasoning and planning, multi-turn conversation, and audio and image understanding through data and algorithmic advances. We see strong improvements on public and internal benchmarks for each of these tasks.1.5 Pro can now follow increasingly complex and nuanced instructions, including ones that specify product-level behavior involving role, format and style. We‚Äôve improved control over the model‚Äôs responses for specific use cases, like crafting the persona and response style of a chat agent or automating workflows through multiple function calls. And we‚Äôve enabled users to steer model behavior by setting system instructions.We added audio understanding in the Gemini API and Google AI Studio, so 1.5 Pro can now reason across image and audio for videos uploaded in Google AI Studio. And we‚Äôre now integrating 1.5 Pro into Google products, including Gemini Advanced and in Workspace apps.Read more about 1.5 Pro in our updated Gemini 1.5 technical report and on the Gemini technology page.Gemini Nano is expanding beyond text-only inputs to include images as well. Starting with Pixel, applications using Gemini Nano with Multimodality will be able to understand the world the way people do ‚Äî not just through text, but also through sight, sound and spoken language.Read more about Gemini 1.0 Nano on Android.Today, we‚Äôre also sharing a series of updates to Gemma, our family of open models built from the same research and technology used to create the Gemini models.We‚Äôre announcing Gemma 2, our next generation of open models for responsible AI innovation. Gemma 2 has a new architecture designed for breakthrough performance and efficiency, and will be available in new sizes.The Gemma family is also expanding with PaliGemma, our first vision-language model inspired by PaLI-3. And we‚Äôve upgraded our Responsible Generative AI Toolkit with LLM Comparator for evaluating the quality of model responses.Read more on the Developer blog.As part of Google DeepMind‚Äôs mission to build AI responsibly to benefit humanity, we‚Äôve always wanted to develop universal AI agents that can be helpful in everyday life. That‚Äôs why today, we‚Äôre sharing our progress in building the future of AI assistants with Project Astra (advanced seeing and talking responsive agent).To be truly useful, an agent needs to understand and respond to the complex and dynamic world just like people do ‚Äî and take in and remember what it sees and hears to understand context and take action. It also needs to be proactive, teachable and personal, so users can talk to it naturally and without lag or delay.While we‚Äôve made incredible progress developing AI systems that can understand multimodal information, getting response time down to something conversational is a difficult engineering challenge. Over the past few years, we‚Äôve been working to improve how our models perceive, reason and converse to make the pace and quality of interaction feel more natural.Building on Gemini, we‚Äôve developed prototype agents that can process information faster by continuously encoding video frames, combining the video and speech input into a timeline of events, and caching this information for efficient recall.By leveraging our leading speech models, we also enhanced how they sound, giving the agents a wider range of intonations. These agents can better understand the context they‚Äôre being used in, and respond quickly, in conversation.With technology like this, it‚Äôs easy to envision a future where people could have an expert AI assistant by their side, through a phone or glasses. And some of these capabilities are coming to Google products, like the Gemini app and web experience, later this year.We‚Äôve made incredible progress so far with our family of Gemini models, and we‚Äôre always striving to advance the state-of-the-art even further. By investing in a relentless production line of innovation, we‚Äôre able to explore new ideas at the frontier, while also unlocking the possibility of new and exciting Gemini use cases.Learn more about Gemini and its capabilities. Your information will be used in accordance with Google‚Äôs privacy policy.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      Done. Just one step more.
    
      Check your inbox to confirm your subscription.
    You are already subscribed to our newsletter.
    You can also subscribe with a
    different email address
    
    .
    
  Let‚Äôs stay in touch. Get the latest news from Google in your inbox.
          Follow Us
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[We‚Äôre sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://tlnagy.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://tlnagy.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://tlnagy.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[<h3>External Posts on Your al-folio¬†Blog</h3> <p>If you prefer publishing blog posts on medium.com or other external sources, starting version v0.5.0, <a href="https://github.com/alshedivat/al-folio">al-folio</a> lets you to display your external posts in the blog feed of your website!¬†üéâüéâ</p> <p>Configuring external sources of super simple. After upgrading to v0.5.0, just add the following section to your _config.yml:</p> <pre>external_sources:<br />  - name: medium.com  # name of the source (arbitrary string)<br />    rss_url: <a href="https://medium.com/@al-folio/feed">https://medium.com/@&lt;your-medium-username&gt;/feed</a></pre> <p>The example above adds your medium.com blog post feed as an external source. But you can add arbitrary RSS feeds as¬†sources.</p> <p>Any questions or suggestions? üëâ Start <a href="https://github.com/alshedivat/al-folio/discussions">a discussion on¬†GitHub</a>!</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b60a1d241a0a" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Inside Lines Equipment Porteur Rackbag Review</title><link href="https://tlnagy.github.io/blog/2018/ile-rackbag/" rel="alternate" type="text/html" title="Inside Lines Equipment Porteur Rackbag Review"/><published>2018-10-13T12:00:00+00:00</published><updated>2018-10-13T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2018/ile-rackbag</id><content type="html" xml:base="https://tlnagy.github.io/blog/2018/ile-rackbag/"><![CDATA[<p>Cycling around San Francisco almost everyday for the past year and a half made me want to look for a better way to carry stuff with me.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0842.JPG" alt=""/></p> <p>I tried the rear rack with baskets approach, but I kept clipping my heels on the baskets and having lots of weight in the back made my bike fish tail too much for my liking. It especially made the bike handle poorly at low speeds and when walking the bike since I hold the bike by the stem<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>.</p> <p>Convinced, I picked up a front porteur rack, the <a href="https://www.amazon.com/Origin8-Classique-Cargo-Front-Rack/dp/B00B135SSE">Origin 8 Classique</a>, and immediately preferred it to my old rear rack set up. However, I realized quickly that my bungee cord solution for attaching stuff to the front rack left a lot to be desired.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0836.JPG" alt=""/></p> <p>After looking at a lot of different porteur bags, I ended up swinging by <a href="https://ilequipment.com/">Inside Lines Equipment</a>‚Äôs shop over in Berkeley and played around with their made-in-Berkeley Rackbag. They had it in a beautiful limited-edition copper/gold color in the XPAC material with a fully waterproof tarpulin liner. Unlike the other XPAC colors, this color was matte and did not have that technical-looking sheen to it. XPAC is a great bag material, it feels very solid and holds its shape well, while also being lightweight. I had to get it and now that I‚Äôve had it for about two weeks I thought I would give a quick review of what I like and what I don‚Äôt.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0840.JPG" alt=""/></p> <p>One of my favorite features are the two easily accessible pockets at the rear of the bag that face you while on the bike. These are great for storing things that you need to be easily accessible on the go. I keep my Abus U-lock in one pocket and miscellaneous things I need in the other. They are quite large and you can easily fit even large snacks, smartphones, etc.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0864.JPG" alt=""/></p> <p>It attaches via two easily adjustable straps on the bottom of the bag. Once you set them to work for your rack, you can attach it and go pretty quickly. I can attach it based on feel now so I don‚Äôt need to squat down any more to attach it.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0866.JPG" alt=""/></p> <p>Let me go ahead and say that this bag is huge, it can expand to hold 42L of your stuff. You‚Äôll probably hit the weight limits of your front rack before filling this thing up. It has some straps hidden in the velco flap to strap on oversized items.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0865.JPG" alt=""/></p> <p>Like any porteur bag, it looks the most at home on the bike, but it can pass as a messenger bag whenever you need to leave the bike behind. The flat, rigid base makes it have unique profile that might not be for everyone.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0867.JPG" alt=""/></p> <p>However, that leads me to probably my least favorite aspects of the bag: there isn‚Äôt a good hand hold if the shoulder strap is attached. They include a nice grab strap, but that can only be used in place of the the shoulder strap, not in addition to. The only other complaint I have is that it would be nice to have some kind of organization inside the main pocket because everything just jostles in the same cavernous hole.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0868.JPG" alt=""/></p> <p>Overall, I‚Äôm very happy with my purchase. It very freeing to not have to put everything on my back while riding and I find that I much prefer having the weight in the front. The ILE Porteur Rackbag is a high-quality, lightweight, versatile, and waterproof bag that I‚Äôm sure will last me a very long time.</p> <p><img src="/assets/images/2018-10-13-ile-rackbag/IMG_0841.JPG" alt=""/></p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p><a href="https://cetmacargo.com/pages/cetma-racks-info">Cetma Cargo</a>‚Äôs reasons for preferring a front rack, in case the link goes down</p> <blockquote> <p>Four barely compelling reasons for using a front rack:</p> <ol> <li> <p>The rear wheel is inherently weaker than the front wheel due to its asymmetrical build, offset hub, and torque input.</p> </li> <li> <p>The rear part of the frame is where almost all frames break. The thin chain stays and seat stays are notorious weak spots.</p> </li> <li> <p>Carrying weight on a rear rack makes the entire bike feel unstable and top-heavy. Put a heavy box on a rear rack and try to ride down the street. The entire frame flexes and the bike tries to lay down. Come to a stop and it gets downright scary. Transporting that box becomes a precarious balancing act. It‚Äôs easier to handle cargo when it‚Äôs up front near your hands.</p> </li> <li> <p>Rear-loaded freight remains behind you while you ride (duh), and you can‚Äôt see if it‚Äôs shifting or about to fall. It‚Äôs easier to keep an eye on cargo when it‚Äôs in front of you.)</p> </li> </ol> <p>- Cetma Cargo</p> </blockquote> <p><a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Tamas Nagy</name></author><category term="cycling"/><category term="review"/><summary type="html"><![CDATA[Cycling around San Francisco almost everyday for the past year and a half made me want to look for a better way to carry stuff with me.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tlnagy.github.io/2018-10-13-ile-rackbag/IMG_0841.JPG"/><media:content medium="image" url="https://tlnagy.github.io/2018-10-13-ile-rackbag/IMG_0841.JPG" xmlns:media="http://search.yahoo.com/mrss/"/></entry><entry><title type="html">A deep dive into the Stellar public network (Part 1)</title><link href="https://tlnagy.github.io/blog/2018/stellar-network-analysis/" rel="alternate" type="text/html" title="A deep dive into the Stellar public network (Part 1)"/><published>2018-03-18T12:00:00+00:00</published><updated>2018-03-18T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2018/stellar-network-analysis</id><content type="html" xml:base="https://tlnagy.github.io/blog/2018/stellar-network-analysis/"><![CDATA[<p>One of the basic tenets of public blockchains is that all account and transactional information is open to anyone to see. While I‚Äôm pretty certain that most cryptocurrencies will eventually adopt some type of zero-knowledge cryptography (e.g. <a href="https://z.cash/technology/zksnarks.html">zk-snarks</a>) that would make this sort of analysis impossible or much more difficult, many still have everything recorded in the clear, e.g. the <a href="https://stellar.org">Stellar network</a> and its corresponding currency, Lumens (XLM).</p> <p>Stellar is an interesting project because it does not rely on the extremely wasteful proof-of-work consensus method (used by Bitcoin and Ethereum). It instead uses the Stellar Consensus Protocol (SCP), which is a form of a federated Byzantine agreement. There‚Äôs a <a href="https://medium.com/a-stellar-journey/on-worldwide-consensus-359e9eb3e949">technical summary</a> and a <a href="https://www.stellar.org/papers/stellar-consensus-protocol.pdf">white paper</a> that both explain how SCP works<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>. Its key benefits are that it is both fast (1000+ transactions per second) and environmentally friendly (extremely low energy costs).</p> <p><strong>Okay, so Stellar is cool, but how are people using it?</strong> This was the question that spawned this analysis. I wanted to see what I could find out from the Stellar‚Äôs public blockchain about how people (and bots) were using it. This is part 1 of what I hope is a multipart dive into the Stellar network<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>. Some questions I hope to answer:</p> <ol> <li><a href="#account-inflation-destination-distribution">What is the inflation destination distribution across accounts?</a></li> <li><a href="#correlation-between-account-balance-and-age">Is there a correlation between account balance and age?</a></li> <li>Are most accounts just holding<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup> lumens or are they actually moving around?</li> <li>What is the topology of the transaction graph? Is it more hub-and-spoke or more Erd≈ës-R√©nyi like?</li> <li>Can I detect when major giveaways and changes to the protocol happened?</li> </ol> <h2 id="getting-the-data">Getting the data</h2> <p>While Stellar‚Äôs documentation is surprisingly good compared to other cryptoprojects, it took a bit of finagling to get everything to work, but that might be more indicative of my newness to the whole scene.</p> <p>The first step was actually getting the data. Stellar has a convenient RESTful API for many things via <a href="https://github.com/stellar/horizon">Horizon</a>, but that isn‚Äôt <a href="https://stellar.stackexchange.com/questions/729/possible-to-get-a-list-of-account-holders-satisfying-certain-criteria-using-hori?noredirect=1#comment597_729">sufficient</a> for my needs so I needed to set up a full node locally.</p> <h3 id="setting-up-a-local-node">Setting up a local node</h3> <p>The easiest way to do this is via <a href="https://www.docker.com/"><code class="language-plaintext highlighter-rouge">Docker</code></a> and once you install it, provisioning a Stellar node is a easy<sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup> as running the following command in your terminal (don‚Äôt type the preceding <code class="language-plaintext highlighter-rouge">$</code>):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker run --rm -it -p "8000:8000" -p "5432:5432" -v ~/Documents/stellar:/opt/stellar --name stellar stellar/quickstart --pubnet
</code></pre></div></div> <p><strong>Make sure to enter a password in for the PostgreSQL database and that you write it down. You‚Äôll need it to connect to the database later.</strong></p> <p>The above command tells Docker to download the <a href="https://github.com/stellar/docker-stellar-core-horizon"><code class="language-plaintext highlighter-rouge">stellar/quickstart</code></a> Docker image and create a volume at <code class="language-plaintext highlighter-rouge">~/Documents/stellar</code> where the Stellar node will store all of its data. It will also expose the HTML and PostgreSQL ports locally too. We‚Äôll need the latter one to actually access the data. Finally, the <code class="language-plaintext highlighter-rouge">--pubnet</code> flag tells the node to use the public network (i.e. real lumens).</p> <p>Once you run this command you‚Äôll need to wait till the node is synchronized with the network. You can check its progress by connecting to the Docker container</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ docker exec -it stellar /bin/bash
</code></pre></div></div> <p>which opens a connection to the container‚Äôs shell. You can then run</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ stellar-core --c 'info'
</code></pre></div></div> <p>to ask query the state of your node. The key thing is to look at the <code class="language-plaintext highlighter-rouge">"state"</code> value below, it should eventually read <code class="language-plaintext highlighter-rouge">"Synced!"</code></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Content-Length: 761
Content-Type: application/json

2018-03-18T02:55:14.579 GACID [default INFO] {
   "info" : {
      "authenticated_peers_count" : 8,
      "build" : "v9.1.0",
      "ledger" : {
         "age" : 8,
         "baseFee" : 100,
         "baseReserve" : 5000000,
         "closeTime" : 1521341706,
         "hash" : "260f4e039fb7835c376b0402fec928049c2071412c1fdfcf220445b67a95ad7e",
         "num" : 16874829,
         "version" : 9
      },
      "network" : "Public Global Stellar Network ; September 2015",
      "pending_peers_count" : 0,
      "protocol_version" : 9,
      "quorum" : {
         "16874828" : {
            "agree" : 5,
            "disagree" : 0,
            "fail_at" : 2,
            "hash" : "ba2fc8",
            "missing" : 0,
            "phase" : "EXTERNALIZE"
         }
      },
      "state" : "Synced!"
   }
}
</code></pre></div></div> <p>The last ledger was <a href="https://stellarchain.io/ledger/16874860">16874860</a> when I shutdown my node to prevent the data from mutating during my analysis.</p> <h3 id="querying-the-data">Querying the data</h3> <p>I used <a href="https://eggerapps.at/postico/">Postico</a> to actually query the data, but any PostgreSQL client will work.</p> <p><img src="/assets/images/2018-03-18-stellar-network-analysis/f6930827.png" alt=""/></p> <p>You‚Äôll need to tell it to connect to the PostgreSQL instance by telling it to connect to localhost on port 5432, with <code class="language-plaintext highlighter-rouge">stellar</code> as the username and the password you entered from above. The main database we‚Äôll be interacting with is <code class="language-plaintext highlighter-rouge">core</code>. You can then execute any SQL query against the database.</p> <h2 id="analysis">Analysis</h2> <p>Now to the fun part, actually answering some questions! All my analysis was done in <a href="https://julialang.org">Julia</a> and my jupyter notebook is available <a href="https://gist.github.com/tlnagy/13c88fb4987ab4081cbc043b31a5e018">here</a>.</p> <h3 id="account-inflation-destination-distribution">Account inflation destination distribution</h3> <p>One major concept of the Stellar network is the concept of <a href="https://www.stellar.org/developers/guides/concepts/inflation.html">inflation</a>.</p> <blockquote> <p>The Stellar distributed network has a built-in, fixed, nominal inflation mechanism. New lumens are added to the network at the rate of 1% each year. Each week, the protocol distributes these lumens to any account that gets over .05% of the ‚Äúvotes‚Äù from other accounts in the network.</p> </blockquote> <p>My understanding is that lumens that are distributed are both new lumens that are added (at the rate of 1% of each year) and the lumens collected from transaction fees<sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">5</a></sup>. But‚Ä¶lumens are only distributed if an inflation destination is set. I wanted to look at the inflation destinations ordered by the total amount of XLM in the accounts pointed at each destination (on left) and the number of accounts pointed at each destination (on right).</p> <p><img src="/assets/images/2018-03-18-stellar-network-analysis/inflationdest.svg" alt=""/></p> <p>First thing, there are a lot of accounts without a set inflation destination (i.e. a NULL destination). 6.7 billion lumens are not earning inflation, which works out to 37% of all distributed lumens. It‚Äôs even worse if you look at the level of accounts. 76% percent of all accounts aren‚Äôt earning any inflation! The biggest community pool (balance-wise) is <a href="https://lumenaut.net/">GCCD..NAUT</a>, which is one of the newer pools that has no fees. Pretty cool that it caught on so quick.</p> <p>I don‚Äôt understand why manual setting of the inflation destination is necessary. Why can‚Äôt the lumens be distributed to every account equally? I just find it unfortunate that the majority of accounts aren‚Äôt taking advantage of the inflation payouts.</p> <h3 id="correlation-between-account-balance-and-age">Correlation between account balance and age</h3> <p>Another thing I wanted to look at is if there was any correlation between the age of an account and the size of the balance. The account creation time is not stored, but there is a last modified time. Plotting the 2D histogram of the last modified time versus balance size gives this:</p> <p><img src="/assets/images/2018-03-18-stellar-network-analysis/balanceage.svg" alt=""/></p> <p>Couple interesting points. You can clearly see when the minimum account balance was lowered from 10 XLM to 0.5 XLM in <a href="https://github.com/stellar/docs/commit/9c0100d80d32dfff9d9d071b77def6bf8599b151#diff-fe29f1f4bf5e6ceed24a2a27a5d241c6">January</a>. There is also a strip around 5000 XLM, which are probably old accounts that received free lumens, but were forgotten.</p> <p>In the next part, I‚Äôll map transactions to each account so then I‚Äôll be able to find the oldest transaction for each account to determine its age instead of using the last modified time. I also hope to answer the rest of the questions outlined above.</p> <p>If you made it this far and have any more ideas for what I could look into, tweet at me (<a href="https://twitter.com/tlngy">\@tlngy</a>).</p> <p>some time in the future. Hopefully, it will help me a better understanding of the limitations and weaknesses of the protocol design.</p> <p>locally on my MacOS machine, but ran into issues with the <a href="https://stellar.stackexchange.com/questions/731/running-into-an-invalid-quorum-set-error-when-running-stellar-core?noredirect=1#comment594_731">config file</a>. Apparently, the default config file ships with a non-functional quorum-set (probably a good thing to make sure people actually think about which nodes they list here, heh).</p> <p>the miners.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>I plan to write an intuitive description of how SCP works on this blog¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>That depends heavily on the amount of free time I have, heh.¬†<a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>hodling¬†<a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:4"> <p>I originally tried setting up an instance by compiling stellar-core¬†<a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:5"> <p>In proof-of-work currencies, the transaction fees are much higher and paid to¬†<a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Tamas Nagy</name></author><category term="crypto"/><summary type="html"><![CDATA[One of the basic tenets of public blockchains is that all account and transactional information is open to anyone to see. While I‚Äôm pretty certain that most cryptocurrencies will eventually adopt some type of zero-knowledge cryptography (e.g. zk-snarks) that would make this sort of analysis impossible or much more difficult, many still have everything recorded in the clear, e.g. the Stellar network and its corresponding currency, Lumens (XLM).]]></summary></entry><entry><title type="html">Keeping a reading list</title><link href="https://tlnagy.github.io/blog/2018/reading-list/" rel="alternate" type="text/html" title="Keeping a reading list"/><published>2018-01-29T12:00:00+00:00</published><updated>2018-01-29T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2018/reading-list</id><content type="html" xml:base="https://tlnagy.github.io/blog/2018/reading-list/"><![CDATA[<p><img src="/assets/images/IMG_20180129_192927.jpg" alt=""/></p> <p><br/></p> <p>I recently received as a gift a replacement for my long deceased third- generation Kindle. As I restart my reading habit with my new friend, I thought it would be nice to begin keeping a reading list. One that would include, not only what I have read, but also what I‚Äôm planning to read. And as I move items to the ‚ÄúHave Read‚Äù section, I plan to write a few sentences to jog my memory about each book in the future. This way I might be able to stave off some of the fogginess that comes with time.</p> <p><br/></p> <p>My target audience with this endeavor is myself, but perhaps you can find something interesting in it as well. Take a <a href="/reading/">look</a>.</p>]]></content><author><name>Tamas Nagy</name></author><category term="meta"/><summary type="html"><![CDATA[]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tlnagy.github.io/IMG_20180129_192927.jpg"/><media:content medium="image" url="https://tlnagy.github.io/IMG_20180129_192927.jpg" xmlns:media="http://search.yahoo.com/mrss/"/></entry><entry><title type="html">UCSF should match employee donations to SFBike</title><link href="https://tlnagy.github.io/blog/2017/ucsf-sfbike-match/" rel="alternate" type="text/html" title="UCSF should match employee donations to SFBike"/><published>2017-12-17T12:00:00+00:00</published><updated>2017-12-17T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2017/ucsf-sfbike-match</id><content type="html" xml:base="https://tlnagy.github.io/blog/2017/ucsf-sfbike-match/"><![CDATA[<p>Cycling is a great way to commute to work and to stay healthy. It is associated with reduced risk for cardiovascular disease, cancer, and all cause mortality [@Celis-Morales2017]. UCSF already recognizes this and <a href="http://campuslifeservices.ucsf.edu/transportation/services/biking">promotes biking</a> as a transportation mode. Citywide, bikes make up about <a href="https://www.sfmta.com/blog/san-francisco%E2%80%99s-surge-biking-continues">4.4% of all commute trips</a> (as of 2014).</p> <p>Unfortunately, the cycling infrastructure in San Francisco still needs a lot of work to be a viable option for students and staff. Too many people are <a href="http://sfgov.org/scorecards/traffic-fatalities">injured or killed</a> each year on our streets. We only have <a href="https://www.sfmta.com/blog/san-francisco%E2%80%99s-surge-biking-continues">13 miles of protected bike lanes</a> and a single protected intersection in the entire city. Researchers in Montreal have found that such infrastructure is used 2.5x times more often than the unprotected bike lanes common in San Francisco [@Lusk2011]. Thus, in order to grow the cycling mode-share among UCSF employees, university officials should also focus on advocating in City Hall to get better infrastructure built. As the second biggest employer within the city limits, UCSF‚Äôs desires carry a lot of weight and pushing for better, safer infrastructure would benefit the health of the city‚Äôs population.</p> <p>It is especially pressing now that we have our first Ford GoBike station at Mission Bay and we‚Äôre slated to get three more in 2018, plus the first one at Parnassus soon after. It would be a mistake to not ramp up advocacy at the same time to ensure that students and staff feel comfortable and safe while using bike share around our campuses.</p> <p>There is already a group dedicated to promoting cycling as a transportation mode within San Francisco, the San Francisco Bike Coalition. They <a href="http://www.sfbike.org/our-work/">advocate</a> for better infrastructure and help train people in urban biking. They have a great presence at City Hall. UCSF already offers a small <a href="http://campuslifeservices.ucsf.edu/transportation/services/biking">discount</a> to join the SF Bike Coalition. I believe UCSF should go further and offer to match student and staff donations to SF Bike. A $35 donation plus a $35 match would go further than than a discount on the $35 membership.</p> <p>Our tagline is</p> <blockquote> <p>UCSF: Advancing Health Worldwide</p> </blockquote> <p>Matching employee donations would help advance health here in San Francisco among UCSF‚Äôs own personnel by making bike commuting more attractive and more common.</p> <h2 id="references">References</h2>]]></content><author><name>Tamas Nagy</name></author><category term="random"/><summary type="html"><![CDATA[Cycling is a great way to commute to work and to stay healthy. It is associated with reduced risk for cardiovascular disease, cancer, and all cause mortality [@Celis-Morales2017]. UCSF already recognizes this and promotes biking as a transportation mode. Citywide, bikes make up about 4.4% of all commute trips (as of 2014).]]></summary></entry><entry><title type="html">Active matter modeling</title><link href="https://tlnagy.github.io/blog/2017/microtubule-vortices/" rel="alternate" type="text/html" title="Active matter modeling"/><published>2017-09-07T12:00:00+00:00</published><updated>2017-09-07T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2017/microtubule-vortices</id><content type="html" xml:base="https://tlnagy.github.io/blog/2017/microtubule-vortices/"><![CDATA[<p>Yesterday was the systems biology module of the iPQB bootcamp here at UCSF. I was in charge of the modeling section and I decided to try to get the students to model the relatively simple active matter system from @Sumino2012-dc since it was relatively straightforward, very visual, and shows complex emergent properties from simple rules (See Figure 1). Active matter systems are ubiquitous nonequilibrium condensed systems whose ‚Äúunifying characteristic is that they are <strong>composed of self-driven units, active particles, each capable of converting stored or ambient free energy into systematic movement</strong>‚Äù [@Marchetti2013]. An <em>in vitro</em> microtubule and dynein system, like the one we‚Äôre investigating here, is much more controlled and reproducible compared to the flocking of birds or fish and thus serves as a nice model system in which to study active matter.</p> <p><img src="/assets/images/2017-09-07-microtubule-vortices/0de43a55.png" alt="Figure 1A-B from @Sumino2012-dc. Cy3 labeled microtubules form vortices when placed on dynein-c coated glass coverslips in the presence of ATP"/></p> <p>The authors proposed a relatively simple model that could recapitulate this phenomenon. They modeled the behavior of the microtubules as a biased Ornstein‚ÄìUhlenbeck process where the microtubules moved at a constant velocity in a direction, $\theta_i$, that was updated by an angular velocity, $\omega_i$, at each time step. They added some normal brownian noise to $\omega_i$ with mean $\xi_{\mu}$ and standard deviation $\xi_{\sigma}$. They noticed that the microtubules had a slight clockwise curvature preference and that after relaxation time $\lambda$, the angular velocity $\omega_i$ would approach the preferred angular velocity, $\omega_0$.</p> <p>@Sumino2012-dc also noted that microtubules would almost always align or anti-align after collisions (they would sometimes stall or cross). They modeled this by taking the aggregate angle of all neighbors of a microtubule that are within a certain distance from the microtubule. This was then weighted by a parameter $A$ that controls the relative influence of other microtubules.</p> <p>Mathematically, this can be expressed in the following non-dimensionalized form:</p> \[\begin{align} \frac{d\Omega_i}{dT} &amp;= - \frac{1}{\lambda}\left(\Omega_i - \Omega_0\right) + \textrm{Normal}(\xi_{\mu}, \xi_{\sigma})\\ \frac{d\theta_i}{dT} &amp;= \Omega_i + \frac{A}{N_i(T)} \sum_{j \sim i} \sin\left(2(\theta_j - \theta_i)\right) \\ \frac{d\mathbf{X_i}}{dT} &amp;= \mathbf{e_x}\cos \theta_i + \mathbf{e_y} \sin \theta_i \end{align}\] <p>I implemented the code using Python 3, NumPy, SciPy, and Matplotlib and it is available as a Jupyter Notebook in this gist: <a href="https://gist.github.com/tlnagy/cba938ffd5c98236e90bfd1dc3d23d11">https://gist.github.com/tlnagy/cba938ffd5c98236e90bfd1dc3d23d11</a>. The students found a quite few parameter combinations that yielded interesting results, most of which were highly unrealistic. I suspect this is due to the much lower ‚Äúconcentration‚Äù of microtubules that we used in our simulation to achieve interactivity, $N=1500$ instead of $N=2621440$. We were still able to get vortices to form:</p> <p><img src="/assets/images/2017-09-07-microtubule-vortices/mt_initial.gif" alt="Initially, microtubule movement looks pretty random."/></p> <p><img src="/assets/images/2017-09-07-microtubule-vortices/mt_vortices.gif" alt="However, they start to coalesce into a grid of vortices"/></p> <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> <h2 id="references">References</h2>]]></content><author><name>Tamas Nagy</name></author><category term="science"/><category term="math"/><summary type="html"><![CDATA[Yesterday was the systems biology module of the iPQB bootcamp here at UCSF. I was in charge of the modeling section and I decided to try to get the students to model the relatively simple active matter system from @Sumino2012-dc since it was relatively straightforward, very visual, and shows complex emergent properties from simple rules (See Figure 1). Active matter systems are ubiquitous nonequilibrium condensed systems whose ‚Äúunifying characteristic is that they are composed of self-driven units, active particles, each capable of converting stored or ambient free energy into systematic movement‚Äù [@Marchetti2013]. An in vitro microtubule and dynein system, like the one we‚Äôre investigating here, is much more controlled and reproducible compared to the flocking of birds or fish and thus serves as a nice model system in which to study active matter.]]></summary></entry><entry><title type="html">Copper Creek and Lower Paradise Valley Trip Report</title><link href="https://tlnagy.github.io/blog/2017/kings-canyon-trip-report/" rel="alternate" type="text/html" title="Copper Creek and Lower Paradise Valley Trip Report"/><published>2017-07-02T12:00:00+00:00</published><updated>2017-07-02T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2017/kings-canyon-trip-report</id><content type="html" xml:base="https://tlnagy.github.io/blog/2017/kings-canyon-trip-report/"><![CDATA[<blockquote> <p>Nature is ever at work building and pulling down, creating and destroying, keeping everything whirling and flowing, allowing no rest but in rhythmical motion, chasing everything in endless song out of one beautiful form into another.</p> <p>‚Äì John Muir in <a href="http://vault.sierraclub.org/john_muir_exhibit/writings/our_national_parks/chapter_3.aspx">Our National Parks, Chapter 3</a></p> </blockquote> <p>This has been a crazy year in the Sierras. We‚Äôve had record snowfall and now everything is melting and <a href="http://www.latimes.com/local/lanow/la-me-ln-kings-river-flooding-snowpack-20170626-story.html">flooding like crazy</a>. The rivers are swollen and the falls are roaring so we thought we had to get out and experience it.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170625_134943.jpg" alt="The view from Lower Paradise Valley, Kings Canyon NP"/></p> <p>We left late last Friday night, June 23rd, at around 7pm from San Francisco. We picked up Alex and Leslie down in Burlingame and aimed the car towards the Sierras. The drive over to Kings Canyon was fairly uneventful. Traffic was light and the weather was good, but very hot in the Central Valley. As we gained altitude, the temps dropped to be a more reasonable 60s-70s, but it was also close to 12:30am at this point. All the campgrounds in Kings Canyon were full so we pitched our tents next to the road in Sequoia National Forest and went to sleep dreaming about the next day.</p> <p>It was slow going the next morning as Andrea and I were pretty tired, but Alex and Leslie were already up and ready to roll out. We still had a bit of driving to do, but what a drive it was. The 180 carves back and forth on the south side of the canyon with imposing granite monoliths on either side and the ferocious Kings River pummeling away at the rocks below. Wildflowers, in stark contrast with this savagery, were in full bloom, all decked out in their royal purples and pinks.</p> <p>We kept going, engine roaring away as we climbed. The road then passed over to the north side of the canyon and it dropped nearly to the level of the river. This is where you could really feel its raw power. The Kings held nothing back. The river was completely white with fury. Trees held on for dear life as the ground beneath them was swept away, but it was only a matter of time. The Kings River will win.</p> <p>The road, as if sensing that it should leave before it too was washed away, then curved away from the river. We passed through some beautiful evergreen forests and enjoyed the gentler incline. We were in the valley proper. We could see massive granite piles peaking out from between the trees and rising thousands of feet vertically from the valley floor. But then, abruptly, we ran out of asphalt. We had reached the road‚Äôs end.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170624_095843.jpg" alt="At Road's End"/></p> <p>We had wanted to do part of the Rae Lakes Loop in Kings Canyon National Park, but after talking to the rangers we learned that the recent snowmelt had wrecked havok on that area. Bridges were washed away, trails were flooded, and they had years worth of work to repair everything. We decided that we should hike the Copper Creek trail since it was one of the least affected by the flooding.</p> <p>We started up the trail around 10am. It was already in high 80s and sun was beating down on us. The trail starts off at a breakneck pace upwards climbing 1000+ feet a mile. The flora was very Mediterranean in nature and bone dry. It did not provide us with much cover from the sun, but thankfully the clouds rolled in and cooled us off with some light showers.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170624_135938.jpg" alt="Andrea and me; cloud worshippers"/></p> <p>The heat, altitude (close to 8000 feet at this point), and lack of sleep got to us. We set up camp close to Lower Tent Meadow about 4 miles in and took a nap. Alex and Leslie kept going, determined to reach Grouse Lake at 10,000 feet. We ended up relaxing most of the afternoon and making dinner before they came back. They turned back once they hit the snow line at 9500 feet. A ranger stopped by our campground and she said that a group further along the trail saw a mother bear and with some cubs and had to scare them off when they got too inquisitive.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170624_203101.jpg" alt="Not the flattest campground"/></p> <p>It was much cooler up here then down below so we slept much better. The next day, we decided to go back down to Road‚Äôs End and do a short day hike up to Mist Falls since the rest of the Copper Creek trail past Upper Tent Meadow was not passable yet. The hike down went very quickly and was fairly uneventful. A highlight was seeing a deer very close to the trail and the magnificent views that we would sometimes get between the trails.</p> <p>We dropped off some of our gear at the car and then headed out towards Mist Falls. It was about 4.7 miles from the trailhead, but the route was fairly flat. The challenge this time came in the form of flooding of the trail and loads of mosquitoes. The insects were unbearable in the wooded areas. They swarmed behind us and if we stopped, even for a couple seconds, we were quickly coated with them. We tried to keep up the pace the whole time. We also ran into quite a few snakes, including a juvenile rattler, likely ousted from their normal dwellings by the raging river.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170625_133449.jpg" alt="The Kings River showed no mercy and neither did the mosquitoes"/></p> <p>Once we made it out of the boggy parts of the trail, the landscape changed dramatically. Granite flows started to dominate and the mosquitoes wilted away. The forest opened up and we were greeted with some of the most picturesque views that I have ever experienced in the Sierras. We stretched out on the warm granite flows and soaked in the warm California sun while Mist Falls roared away behind us.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170625_134939.jpg" alt="This view is priceless"/></p> <p>We even saw a hummingbird investigating some flowers near us. Paradise Valley, indeed.</p> <p><img src="/assets/images/2017-07-02-kings-canyon-trip-report/IMG_20170625_135724.jpg" alt="Hummingbird in paradise"/></p> <p>We had to brave the bogs and mosquitoes on the way back too, but we were mentally prepared for it this time. We slogged through it again and made it back to car with only couple more bites to our name.</p>]]></content><author><name>Tamas Nagy</name></author><category term="trip report"/><summary type="html"><![CDATA[Nature is ever at work building and pulling down, creating and destroying, keeping everything whirling and flowing, allowing no rest but in rhythmical motion, chasing everything in endless song out of one beautiful form into another. ‚Äì John Muir in Our National Parks, Chapter 3]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tlnagy.github.io/2017-07-02-kings-canyon-trip-report/IMG_20170625_134939.jpg"/><media:content medium="image" url="https://tlnagy.github.io/2017-07-02-kings-canyon-trip-report/IMG_20170625_134939.jpg" xmlns:media="http://search.yahoo.com/mrss/"/></entry><entry><title type="html">UCSF Graduate Student Taxes FAQ</title><link href="https://tlnagy.github.io/blog/2017/grad-student-taxes/" rel="alternate" type="text/html" title="UCSF Graduate Student Taxes FAQ"/><published>2017-05-31T12:00:00+00:00</published><updated>2017-05-31T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2017/grad-student-taxes</id><content type="html" xml:base="https://tlnagy.github.io/blog/2017/grad-student-taxes/"><![CDATA[<p>I‚Äôm currently a 2nd year graduate student in the quantitative biology program at UCSF. I am certainly no tax professional<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>, but I thought I would write a bit about what you can expect to pay in taxes at UCSF. These are some questions that I think I would have appreciated knowing the answers to in my first two years<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>.</p> <h3 id="do-we-have-to-pay-taxes">Do we have to pay taxes?</h3> <p>Yes, both state and federal. The tricky part is that while you are paid by UCSF on a 1098-T form (normally for your first two years) nothing is withheld for taxes so you have pay the full amount come April.</p> <h3 id="how-much-should-i-set-aside-each-month-for-taxes">How much should I set aside each month for taxes?</h3> <p>Most estimates are between $400-500 a month depending on your specific situation. I would probably aim for $425.</p> <p>Now assuming that you did not have any external income, you should expect to pay roughly $2000<sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup> in your first year since you are only taxed for October, November, and December. 2nd year you have to pay for the entire year and this works out to being close to $4800. It‚Äôs a lot if you‚Äôre not ready for it.</p> <h3 id="how-much-do-i-actually-owe">How much do I actually owe?</h3> <p>In the simplest case, your ‚Äútaxable income‚Äù is simply the difference between box 5 and box 1 on your 1098-T form. This value will be higher than your stipend since it includes the ‚Äútaxable‚Äù contributions to our health insurance, UC SHIP. You can find your 1098-T at <a href="https://1098t.com">https://1098t.com</a>.</p> <h3 id="how-do-i-e-file-for-free">How do I e-file for free?</h3> <p>There is no need to pay for e-filing since we make less than the limit for <a href="https://apps.irs.gov/app/freeFile/jsp/wizard.jsp?">IRS FreeFile</a>. Just fill out the form and select one of the free filing options. I have had good luck with TaxAct.</p> <h3 id="can-we-withhold-taxes-so-that-april-isnt-such-a-bummer">Can we withhold taxes so that April isn‚Äôt such a bummer?</h3> <p>Yes. In my opinion, the easiest and best way to do this to <a href="https://www.irs.gov/uac/pay-taxes-by-electronic-funds-withdrawal">set up estimated tax payments</a> when you e-file. Your bank account is debited according to whatever estimated tax plan you submit. This is also nice because you do not have to pay the penalty for failing to withhold income<sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup>. Make sure to set up payments to both the IRS and California‚Äôs Franchise Tax Board. This should be quite easy if you are setting this up during e-filing.</p> <h3 id="can-we-contribute-to-a-roth-ira">Can we contribute to a Roth IRA?</h3> <p>Unfortunately, to the best of my knowledge, we cannot. Since the money we make on a 1098-T is considered taxable, unearned income it does not qualify for IRA. According to <a href="https://www.irs.gov/pub/irs-pdf/p590a.pdf">IRS Pub 590-A</a> (Page 6):</p> <blockquote> <p>Scholarship and fellowship payments are compensation for IRA purposes only if shown in box 1 of Form W-2</p> </blockquote> <p>However, the moment you are switched to a W-2, you can contribute up to your earned income amount or $5500, which ever is smaller.</p> <h3 id="what-is-a-roth-ira">What is a Roth IRA?</h3> <p>They are super cool, read more about them <a href="https://www.bogleheads.org/wiki/Roth_IRA">here</a>. Basically, they are a great way to save for retirement as a graduate student. Since we are in a very low tax bracket, you pay our low marginal tax rate now for the money you put in and all future earnings are tax-free for retirement.</p> <h3 id="but-what-if-i-want-to-save-for-more-immediate-things-than-retirement">But what if I want to save for more immediate things than retirement?</h3> <p>Roths can still help you. You can always take the principal (the original money you contributed, not the earnings) out tax-free since you already paid taxes on it. Now I don‚Äôt recommend this since you can‚Äôt put that money back later due to the annual cap of $5500. But in an emergency, you can access the principal. Also, there are exceptions for removing earnings from a Roth without paying the penalty like substantial medical bills, first-time home purchase, etc. You have to be more careful with the rules here, see <a href="http://www.rothira.com/roth-ira-withdrawal-rules">this</a> for more details.</p> <p>club. Thanks Kyle! Update: After I wrote this piece, I found out that Kyle also had a blog post about this a couple years ago: <a href="https://www.kylebarlow.com/dearth-and-taxes.html">https://www.kylebarlow.com/dearth-and-taxes.html</a></p> <p>increases. For reference, in my first two years, we made 34K (TY2015) and then 36K (TY2016).</p> <p>is based on the previous tax year. It will be quite large in your 3rd year if you don‚Äôt set up an estimated tax payment.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>So YMMV on all this depending on your specific circumstances¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>This post was inspired by a presentation by Kyle Barlow at iPQB journal¬†<a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>Naturally, this value will increase if the UCSF graduate student stipend¬†<a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:4"> <p>This penalty was pretty small for me as a 1st and 2nd year because it¬†<a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Tamas Nagy</name></author><category term="random"/><summary type="html"><![CDATA[I‚Äôm currently a 2nd year graduate student in the quantitative biology program at UCSF. I am certainly no tax professional1, but I thought I would write a bit about what you can expect to pay in taxes at UCSF. These are some questions that I think I would have appreciated knowing the answers to in my first two years2. So YMMV on all this depending on your specific circumstances¬†&#8617; This post was inspired by a presentation by Kyle Barlow at iPQB journal¬†&#8617;]]></summary></entry><entry><title type="html">Embedding videos in Google Slides as GIFs</title><link href="https://tlnagy.github.io/blog/2016/videos-in-google-slides-gifs/" rel="alternate" type="text/html" title="Embedding videos in Google Slides as GIFs"/><published>2016-08-15T12:00:00+00:00</published><updated>2016-08-15T12:00:00+00:00</updated><id>https://tlnagy.github.io/blog/2016/videos-in-google-slides-gifs</id><content type="html" xml:base="https://tlnagy.github.io/blog/2016/videos-in-google-slides-gifs/"><![CDATA[<p>In my field, systems biology, it‚Äôs pretty common to take time-lapse movies to get the dynamics of how the system behaves. And we like showing them off. This makes Google Slides<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> inability to embed videos (without uploading them to Youtube) pretty annoying and inconvenient. Slides does, on the other hand, have good support for embedding GIFs. I came up with the following pipeline (based on notedible‚Äôs comment on <a href="https://superuser.com/questions/556029/how-do-i-convert-a-video-to-gif-using-ffmpeg-with-reasonable-quality">Stackoverflow</a>). First, make sure to install <code class="language-plaintext highlighter-rouge">libav</code> and <code class="language-plaintext highlighter-rouge">imagemagick</code>. On Debian-based systems, you can run</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo apt-get install libav-tools imagemagick
</code></pre></div></div> <p>and on MacOS<sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> the easiest way to install them is via <a href="http://brew.sh">homebrew</a>. Then I use the following command to create the GIF:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat some_movie.m4v | avconv -i pipe: -r 10 -f image2pipe -vcodec ppm - | convert -delay 5 -loop 0 - gif:- | convert -layers Optimize - output.gif
</code></pre></div></div> <p>where <code class="language-plaintext highlighter-rouge">some_movie.m4v</code> is the video file. This creates an optimized GIF version called <code class="language-plaintext highlighter-rouge">output.gif</code>, which you can then upload to Google Slides. The last niggle is that the GIFs play continuously and sometimes it‚Äôs helpful to be able to stop/start the playback. Enter the <a href="https://addons.mozilla.org/en-US/firefox/addon/toggle-animated-gifs/">Toggle Animated Gifs</a> extension for Firefox (I‚Äôm sure there‚Äôs something comparable for Chrome), which lets you do just that.</p> <h2 id="addendum-17-04-28">Addendum 17-04-28</h2> <p>If you get an error that looks like the following with some weirdly formatted <code class="language-plaintext highlighter-rouge">.mov</code> files:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>avconv version 12, Copyright (c) 2000-2016 the Libav developers
  built on Mar  6 2017 22:35:59 with Apple LLVM version 8.0.0 (clang-800.0.42.1)
[mov,mp4,m4a,3gp,3g2,mj2 @ 0x7fc78b000000] stream 0, offset 0x30: partial file
[mov,mp4,m4a,3gp,3g2,mj2 @ 0x7fc78b000000] Could not find codec parameters (Video: mpeg4 (Simple Profile) [mp4v / 0x7634706D]
      none, 1958 kb/s)
Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'pipe:':
  Metadata:
    major_brand     : qt
    minor_version   : 537199360
    compatible_brands: qt
    creation_time   : 2015-05-26 19:04:15
  Duration: 00:00:10.00, bitrate: N/A
    Stream #0:0(eng): Video: mpeg4 (Simple Profile) [mp4v / 0x7634706D]
      none, 1958 kb/s
      600 tbn (default)
    Metadata:
      creation_time   : 2015-05-26 19:04:15
      handler_name    : Apple Alias Data Handler
      encoder         : MPEG-4 Video
Output #0, image2pipe, to 'pipe:':
Output file #0 does not contain any stream
convert: no decode delegate for this image format `' @ error/constitute.c/ReadImage/509.
convert: no images defined `gif:-' @ error/convert.c/ConvertImageCommand/3254.
convert: no decode delegate for this image format `' @ error/constitute.c/ReadImage/509.
convert: no images defined `output.gif' @
error/convert.c/ConvertImageCommand/3254. 
</code></pre></div></div> <p>Then installing the <code class="language-plaintext highlighter-rouge">qtfaststart</code><sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup> Python package via <code class="language-plaintext highlighter-rouge">pip install qtfaststart</code> and then running</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>qtfaststart bad_movie.mov good_movie.mov
</code></pre></div></div> <p>should fix the problem and now you can use <code class="language-plaintext highlighter-rouge">good_movie.mov</code> with the previous commands to create all the gifs. So <a href="https://superuser.com/questions/479063/ffmpeg-pipe-input-error/479064#479064">apparently</a> what is happening is that some recording software puts the <code class="language-plaintext highlighter-rouge">mdat</code> block prior to the <code class="language-plaintext highlighter-rouge">moov</code> block (the structural metadata). This is more convenient for recording since the structure isn‚Äôt known till the recording is finished, however for playback it isn‚Äôt as nice. <code class="language-plaintext highlighter-rouge">qtfaststart</code> fixes this by swapping the two blocks:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ qtfaststart -l bad_movie.mov
ftyp (32 bytes)
wide (8 bytes)
mdat (2448358 bytes)
moov (998 bytes)
</code></pre></div></div> <p>while</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>qtfaststart -l good_movie.mov
ftyp (32 bytes)
moov (998 bytes)
wide (8 bytes)
mdat (2448358 bytes)
</code></pre></div></div> <p>its simplicity, portability, and collaboration features. Hard to beat for presentations.</p> <p>qtfaststart.c file. Why ffmpeg can‚Äôt do this on its own? Who knows.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>I like Google Slides for a variety of reasons, but the main ones are¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>OS X dammit¬†<a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>So apparently this Python package just repackages ffmpeg‚Äôs own¬†<a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Tamas Nagy</name></author><category term="science"/><category term="productivity"/><summary type="html"><![CDATA[In my field, systems biology, it‚Äôs pretty common to take time-lapse movies to get the dynamics of how the system behaves. And we like showing them off. This makes Google Slides1 inability to embed videos (without uploading them to Youtube) pretty annoying and inconvenient. Slides does, on the other hand, have good support for embedding GIFs. I came up with the following pipeline (based on notedible‚Äôs comment on Stackoverflow). First, make sure to install libav and imagemagick. On Debian-based systems, you can run I like Google Slides for a variety of reasons, but the main ones are¬†&#8617;]]></summary></entry></feed>